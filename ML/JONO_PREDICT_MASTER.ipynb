{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24755160",
   "metadata": {
    "id": "8c9cb573"
   },
   "source": [
    "MASTER PYTHON - Using the full training set - Running the learning models take 45 minute each, be patient\n",
    "\n",
    "I added a line from FYANGO that take sthe vectorizer to the app that builds teh external question faster\n",
    "\n",
    "All the models are exported\n",
    "\n",
    "2 models, LOG and AggrO\n",
    "\n",
    "Modify the exisitng models reliably predict if new\n",
    "s is fake or real, using exisitng KAGGEL datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca5946",
   "metadata": {
    "id": "4d5dda4c"
   },
   "source": [
    "#### Dataset used - https://www.kaggle.com/fake-news/data\n",
    "\n",
    "### Dataset Description\n",
    "\n",
    "train.csv: A full training dataset with the following attributes:\n",
    "\n",
    "* id: unique id for a news article\n",
    "* title: the title of a news article\n",
    "* author: author of the news article\n",
    "* text: the text of the article; could be incomplete\n",
    "* label: a label that marks the article as potentially unreliable\n",
    "  * 1: FAKE\n",
    "  * 0: TRUE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9612db7e",
   "metadata": {
    "id": "f47d9fde"
   },
   "source": [
    "Ensure the file creator is installed to save the MODELS for use in Heroku app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc05c85b",
   "metadata": {
    "id": "acdf7db5"
   },
   "source": [
    "Set the dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "643aaced",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/jonowood/Project-4-A-Team/blob/JonBranch/ML/JONO_PREDICT_MASTER.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/jonowood/Project-4-A-Team/blob/JonBranch/ML/JONO_PREDICT_MASTER.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" /> Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f313070",
   "metadata": {
    "id": "7b4b4979"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b19d1d8",
   "metadata": {
    "id": "5cbd1c06"
   },
   "source": [
    "The Natural Language Toolkit (NLTK) is a platform used for building Python programs that work with human language data for applying in statistical natural language processing (NLP). It contains text processing libraries for tokenization, parsing, classification, stemming, tagging and semantic reasoning.\n",
    "The nltk.corpus package defines a collection of corpus reader classes, which can be used to access the contents of a diverse set of corpora. The list of available corpora is given at: https://www.nltk.org/nltk_data/ Each corpus reader class is specialized to handle a specific corpus forma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a94e780",
   "metadata": {
    "id": "c32358ea"
   },
   "source": [
    "Load and test all the STW ,Stopwords are words which occur frequently in a corpus. e.g a, an, the, in. Frequently occurring words are removed from the corpus for the purpose of text-normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c392dc4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b3d25c8",
    "outputId": "a174a4ae-f59d-4210-e4b1-32f29afa4c50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jonow\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc9173f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd8da98b",
    "outputId": "2a30bc0b-3d38-431f-dc5a-1be22dfd8839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# check if Stopwords laoded in english\n",
    "\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67432b17",
   "metadata": {
    "id": "a44f0a84"
   },
   "source": [
    "Data Pre-processing and Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1cb37a",
   "metadata": {
    "id": "83fffc5d"
   },
   "source": [
    "Regular Expression Syntax. A regular expression (or RE) specifies a set of strings that matches it; the functions in this module let you check if a particular string matches a given regular expression (or if a given regular expression matches a particular string, which comes down to the same thing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1715fd4d",
   "metadata": {
    "id": "64f87ca9"
   },
   "source": [
    "Load the dataset, Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9791b13",
   "metadata": {
    "id": "a8c855de"
   },
   "outputs": [],
   "source": [
    "# First let's load the dataset\n",
    "news_dataset = pd.read_csv('../Dataset/train.csv',encoding = \"latin-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ecf8fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0c5a95a7",
    "outputId": "f4494ef8-8de7-445f-f1d9-327b73dbf86c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didnât Even See Comeyâs...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didnât Even See Comeyâs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\r\\nAn Iranian woman has been sentenced ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didnât Even See Comeyâs...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didnât Even See Comeyâs...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\r\\nAn Iranian woman has been sentenced ...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "157b2040",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36f74ae7",
    "outputId": "d234ff95-76b9-48a6-bc1a-bae21257aa31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75e3363c",
   "metadata": {
    "id": "3026eca7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didnât Even See Comeyâs...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didnât Even See Comeyâs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\r\\nAn Iranian woman has been sentenced ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didnât Even See Comeyâs...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didnât Even See Comeyâs...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\r\\nAn Iranian woman has been sentenced ...      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all columns between column index 5 to 250\n",
    "news_dataset.drop(news_dataset.iloc[:, 5:251], inplace=True, axis=1)\n",
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df18e2c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecbda73a",
    "outputId": "76cd8094-f435-46b0-9de6-28969e670aeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "news_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "021ba340",
   "metadata": {
    "id": "a38e4563"
   },
   "outputs": [],
   "source": [
    "# Let's replace the missing values with empty strings wherever possible\n",
    "news_dataset = news_dataset.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d32981ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bc21253",
    "outputId": "a436331a-0659-4111-aab7-a5a6c2d4f96d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "title     0\n",
       "author    0\n",
       "text      0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a013446",
   "metadata": {
    "id": "721227d6"
   },
   "source": [
    ":In this dataset the Title, Author indicates validity of the message, various previous works validates teh statement that authnetic authors makes a difference and newsrooms use thsi regulary as key indicators to tack their messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa0abc74",
   "metadata": {
    "id": "68e90c0f"
   },
   "outputs": [],
   "source": [
    "news_dataset['text_corpus'] = news_dataset['author']+' '+news_dataset['title']+' '+news_dataset['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6272cdd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9735166d",
    "outputId": "b4ab17e6-f2fd-4b43-ad0a-4e9b32b30f1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Darrell Lucus House Dem Aide: We Didnât Even...\n",
      "1        Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...\n",
      "2        Consortiumnews.com Why the Truth Might Get You...\n",
      "3        Jessica Purkiss 15 Civilians Killed In Single ...\n",
      "4        Howard Portnoy Iranian woman jailed for fictio...\n",
      "                               ...                        \n",
      "20795    Jerome Hudson Rapper T.I.: Trump a âPoster C...\n",
      "20796    Benjamin Hoffman N.F.L. Playoffs: Schedule, Ma...\n",
      "20797    Michael J. de la Merced and Rachel Abrams Macy...\n",
      "20798    Alex Ansary NATO, Russia To Hold Parallel Exer...\n",
      "20799    David Swanson What Keeps the F-35 Alive   Davi...\n",
      "Name: text_corpus, Length: 20800, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(news_dataset['text_corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19166adb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "96a4b409",
    "outputId": "5ec5b71c-ee54-4982-d1a1-22e3d4ad155b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didnât Even See Comeyâs...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didnât Even See Comeyâs...</td>\n",
       "      <td>1</td>\n",
       "      <td>Darrell Lucus House Dem Aide: We Didnât Even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Consortiumnews.com Why the Truth Might Get You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jessica Purkiss 15 Civilians Killed In Single ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\r\\nAn Iranian woman has been sentenced ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Howard Portnoy Iranian woman jailed for fictio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didnât Even See Comeyâs...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  House Dem Aide: We Didnât Even See Comeyâs...      1   \n",
       "1  Ever get the feeling your life circles the rou...      0   \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1   \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1   \n",
       "4  Print \\r\\nAn Iranian woman has been sentenced ...      1   \n",
       "\n",
       "                                         text_corpus  \n",
       "0  Darrell Lucus House Dem Aide: We Didnât Even...  \n",
       "1  Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...  \n",
       "2  Consortiumnews.com Why the Truth Might Get You...  \n",
       "3  Jessica Purkiss 15 Civilians Killed In Single ...  \n",
       "4  Howard Portnoy Iranian woman jailed for fictio...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c87efc29",
   "metadata": {
    "id": "79df8e1a"
   },
   "outputs": [],
   "source": [
    "# Now we will separate the data and label i.e. text_corpus and label fields\n",
    "X = news_dataset.drop(columns='label', axis=1)\n",
    "Y = news_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c29f003c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6df5e73",
    "outputId": "a44efa82-7fd4-4961-9014-33e48beb730a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Darrell Lucus House Dem Aide: We Didnât Even...\n",
      "1        Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...\n",
      "2        Consortiumnews.com Why the Truth Might Get You...\n",
      "3        Jessica Purkiss 15 Civilians Killed In Single ...\n",
      "4        Howard Portnoy Iranian woman jailed for fictio...\n",
      "                               ...                        \n",
      "20795    Jerome Hudson Rapper T.I.: Trump a âPoster C...\n",
      "20796    Benjamin Hoffman N.F.L. Playoffs: Schedule, Ma...\n",
      "20797    Michael J. de la Merced and Rachel Abrams Macy...\n",
      "20798    Alex Ansary NATO, Russia To Hold Parallel Exer...\n",
      "20799    David Swanson What Keeps the F-35 Alive   Davi...\n",
      "Name: text_corpus, Length: 20800, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X = news_dataset['text_corpus']\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30147f00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5494807c",
    "outputId": "4b82ed2b-0d18-4183-98be-1d9d18dc6758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        0\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "20795    0\n",
      "20796    0\n",
      "20797    0\n",
      "20798    1\n",
      "20799    1\n",
      "Name: label, Length: 20800, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3fb87fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbc09eb1",
    "outputId": "bc50de80-14fb-46b1-d60c-e5b650474c2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Darrell Lucus House Dem Aide: We Didnât Even...\n",
       "1    Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...\n",
       "2    Consortiumnews.com Why the Truth Might Get You...\n",
       "3    Jessica Purkiss 15 Civilians Killed In Single ...\n",
       "4    Howard Portnoy Iranian woman jailed for fictio...\n",
       "Name: text_corpus, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d30c4c",
   "metadata": {
    "id": "25ff91f8"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Stemming or Lemmatization-https://pythonprogramming.net/stemming-nltk-tutorial/\n",
    "\n",
    "Stemming is a technique used to reduce an inflected word down to its word stem. For example, the words “programming,” “programmer,” and “programs” can all be reduced down to the common word stem “program.” In other words, “program” can be used as a synonym for the prior three inflection words\n",
    "\n",
    "Porter’s Stemmer applies a set of five sequential rules (also called phases) to determine common suffixes from sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2590cbad",
   "metadata": {
    "id": "c33c1ca7"
   },
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()\n",
    "\n",
    "def stemming(content):\n",
    "    # Pick all alphabet characters - lowercase and uppercase...all others such as numbers and punctuations will be removed. Numbers or punctuations will be replaced by a whitespace\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
    "    # Converting all letters to lowercase \n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    # Converting all to a splitted case or a list\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    # Applying stemming, so we get the root words wherever possible + remove stopwords as well\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    # Join all the words in final content\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cf1e094",
   "metadata": {
    "id": "d9506e8d"
   },
   "outputs": [],
   "source": [
    "news_dataset['text_corpus'] = news_dataset['text_corpus'].apply(stemming)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad0d38fb",
   "metadata": {},
   "source": [
    "## Getting a coffee, let me know when its done ☕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "534fe8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c785a87a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c94a515a",
    "outputId": "94f125ce-7c72-45c5-9cd7-3282c020b007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        darrel lucu hous dem aid even see comey letter...\n",
      "1        daniel j flynn flynn hillari clinton big woman...\n",
      "2        consortiumnew com truth might get fire truth m...\n",
      "3        jessica purkiss civilian kill singl us airstri...\n",
      "4        howard portnoy iranian woman jail fiction unpu...\n",
      "                               ...                        \n",
      "20795    jerom hudson rapper trump poster child white s...\n",
      "20796    benjamin hoffman n f l playoff schedul matchup...\n",
      "20797    michael j de la merc rachel abram maci said re...\n",
      "20798    alex ansari nato russia hold parallel exercis ...\n",
      "20799    david swanson keep f aliv david swanson author...\n",
      "Name: text_corpus, Length: 20800, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(news_dataset['text_corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "254e3ad7",
   "metadata": {
    "id": "4e6d6315"
   },
   "outputs": [],
   "source": [
    "# Separating data and label\n",
    "X = news_dataset['text_corpus'].values\n",
    "Y = news_dataset['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9ea39e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bccfd6f",
    "outputId": "348064e1-5a9c-4ef7-d7aa-8890de259ec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['darrel lucu hous dem aid even see comey letter jason chaffetz tweet hous dem aid even see comey letter jason chaffetz tweet darrel lucu octob subscrib jason chaffetz stump american fork utah imag courtesi michael jolley avail creativ common licens apolog keith olbermann doubt worst person world week fbi director jame comey accord hous democrat aid look like also know second worst person well turn comey sent infam letter announc fbi look email may relat hillari clinton email server rank democrat relev committe hear comey found via tweet one republican committe chairmen know comey notifi republican chairmen democrat rank member hous intellig judiciari oversight committe agenc review email recent discov order see contain classifi inform long letter went oversight committe chairman jason chaffetz set polit world ablaz tweet fbi dir inform fbi learn exist email appear pertin investig case reopen jason chaffetz jasoninthehous octob cours know case comey actual say review email light unrel case know anthoni weiner sext teenag appar littl thing fact matter chaffetz utah republican alreadi vow initi raft investig hillari win least two year worth possibl entir term worth appar chaffetz thought fbi alreadi work result tweet briefli roil nation cooler head realiz dud accord senior hous democrat aid misread letter may least chaffetz sin aid told shareblu boss democrat even know comey letter time found check twitter democrat rank member relev committe receiv comey letter republican chairmen fact democrat rank member receiv chairman oversight govern reform committe jason chaffetz tweet made public let see got right fbi director tell chaffetz gop committe chairmen major develop potenti polit explos investig neither chaffetz colleagu courtesi let democrat counterpart know instead accord aid made find twitter alreadi talk daili ko comey provid advanc notic letter chaffetz republican give time turn spin machin may make good theater noth far even suggest case noth far suggest comey anyth grossli incompet tone deaf suggest howev chaffetz act way make dan burton darrel issa look like model respons bipartisanship even decenc notifi rank member elijah cum someth explos trampl basic standard fair know grant like chaffetz answer sit ridicul republican district anchor provo orem cook partisan vote index r gave mitt romney punish percent vote moreov republican hous leadership given full support chaffetz plan fish expedit mean turn hot light textbook exampl hous becom republican control also second worst person world darrel lucu darrel someth graduat univers north carolina consid journalist old school attempt turn member religi right colleg succeed turn religi right worst nightmar charismat christian unapologet liber desir stand scare silenc increas surviv abus three year marriag may know daili ko christian dem nc follow twitter darrelllucu connect facebook click buy darrel mello yello connect'\n",
      " 'daniel j flynn flynn hillari clinton big woman campu breitbart ever get feel life circl roundabout rather head straight line toward intend destin hillari clinton remain big woman campu leafi liber wellesley massachusett everywher els vote like inaugur dress remaind day way miss havisham forev wore wed dress speak great expect hillari rodham overflow year ago first address wellesley graduat class presid colleg inform gather student need debat far could ascertain spokesman kind like democrat primari minu term unknown even seven sister school glad miss adam made clear speak today us us miss rodham told classmat appoint edger bergen charli mccarthi mortim snerd attend bespectacl granni glass award matronli wisdom least john lennon wisdom took issu previou speaker despit becom first win elect seat u senat sinc reconstruct edward brook came critic call empathi goal protestor critic tactic though clinton senior thesi saul alinski lament black power demagogu elitist arrog repress intoler within new left similar word come republican necessit brief rebutt trust rodham iron observ one word ask class rehears want say everyon came said talk trust talk lack trust us way feel other talk trust bust say say feel permeat gener perhap even understood distrust trust bust certainli bust clinton plan certainli even understand peopl distrust whitewat travelg vast conspiraci benghazi miss email clinton found distrust voic friday load compromis road broaden polit horizon distrust american peopl trump edg percent percent question immedi prior novemb elect stood major reason close horizon clinton describ vanquish support embrac lie con altern fact assault truth reason fail explain american peopl chose lie truth histori major among today know well peopl power invent fact attack question mark begin end free societi offer hyperbol like mani peopl emerg hillari clinton embark upon long strang trip high school goldwat girl wellesley colleg republican presid democrat politician clinton drank time place gave degre significantli went idealist cynic comparison two wellesley commenc address show way back lament long leader view polit art possibl challeng practic polit art make appear imposs possibl big woman campu odd woman white hous wonder current station even possibl point ahead ask septemb may ask presid woman famous dub congenit liar bill safir conclud lie mind get stood elect day like find jilt bride wed day inspir danger delus'\n",
      " 'consortiumnew com truth might get fire truth might get fire octob tension intellig analyst polit policymak alway honest assess desir result latter often overwhelm former iraq war write lawrenc davidson lawrenc davidson might wonder foreign polici maker repeatedli make bad choic insight might drawn follow analysi action play unit state lesson probabl univers back earli spring georg w bush initi invas iraq one key public reason claim countri dictat saddam hussein verg develop nuclear weapon hide weapon mass destruct real reason went beyond charg includ long rang plan regim chang middl east presid georg w bush vice presid dick cheney receiv oval offic brief cia director georg tenet also present chief staff andi card right white hous photo purpos concentr belief iraq becom hostil nuclear power presid bush close associ accept scenario readili short answer bush want inde need believ rational invad iraq first tri connect saddam hussein attack u though never gave stratagem lack evid made difficult ralli american peopl alreadi fixat afghanistan support war baghdad nuclear weapon gambit prove fruit hard evid charg supposedli reliabl wit person exil anti saddam iraqi mani u govern payrol kept tell bush advis nuclear stori true u leadership cadr whose worldview liter demand mortal danger iraq inform order precipit overthrow saddam will tell tale pend atom weapon strong desir believ tale nuclear iraq lower threshold proof likewis repeat assert assum depend iraqi sourc underpin nationwid u campaign gener fear war fever u alli insist unit nation send weapon inspector scour iraq evid nuclear weapon program well chemic biolog weapon inspector could find convinc evid frustrat bush administr soon forc hand march bush launch invas iraq expect occup countri u inspector would sure find evid nuke least stockpil chemic biolog weapon iraqi inform systemat lie social behavior scienc rescu variou u intellig agenc thoroughli shaken affair today year later director manag still tri sort specif tell get true intellig lie one intellig worker put need help protect us armi snake oil salesmen end cia et al market academ assist ahm chalabi head iraqi nation congress key supplier iraqi defector bogu stori hidden wmd partnership forg offic director nation intellig odni serv coordin center sixteen independ u intellig agenc nation academi scienc engin medicin result collabor perman intellig commun studi board coordin program social behavior scienc research might strengthen nation secur despit effort almost certain social behavior scienc cannot give spi agenc want way detect lie better present standard procedur polygraph test interrog even could might well make differ real problem found liar found believ believ simpli true odni leader seem assert u intellig agenc personnel cannot tell often lie case thousand middl echelon intellig worker desk offic specialist know someth close approach truth know pretti well go place like afghanistan iraq syria libya israel palestin elsewher director nation intellig jame clapper right talk presid barack obama oval offic john brennan nation secur aid present photo credit offic director nation intellig therefor someon feed snake oil usual know howev accur grasp thing often avail superior got appoint accept pre structur worldview differ criterion true analyst listen charl gaukel nation intellig council yet anoth organ act meet ground intellig agenc refer search way avoid get taken lie gaukel declar look truth particularli look truth work might mean certainli tell mean histor mean power broker truth must match fit worldview polit ideolog precept fit work intellig specialist send usual accur assess line polici maker often hit roadblock caus group think ideolog blinker know better attitud hand long sell leadership match want believ peddl anyth imaginari iraqi nuke israel western style democraci saudi arabia indispens alli libya liber countri bashar al assad real roadblock peac syria strateg defens initi sdi aka star war world get colder warmer american exception glori list almost endless sad tale tell us want spend million dollar social behavior scienc research improv assess use intellig forget liar want look antidot narrow minded believ policymak seem abl rise ideolog presumpt class presumpt underpin self confid lead us slipperi slope happen way often mani place sourc shakespear determin past prelud elit play destini free capac break structur way see yet middl echelon specialist keep send rel accur assess ladder power hope spring etern'\n",
      " ...\n",
      " 'michael j de la merc rachel abram maci said receiv takeov approach hudson bay new york time maci today grew union sever great name american retail includ namesak chain bloomingdal marshal field ambiti owner sak fifth avenu broach idea take union even combin maci creat depart store juggernaut time industri reel hudson bay compani canadian owner sak approach maci potenti takeov peopl brief matter author speak publicli said friday talk two compani earli stage may still fall apart lead partnership kind rather sale unclear whether deal happen combin could lift fortun maci countri biggest depart store struggl investor certainli appear see way share maci rose much percent friday biggest intraday gain sinc aug accord data bloomberg retail titan maci struggl remain relev discount retail decim tradit busi last month maci announc plan cut job close store terri lundgren chief execut architect maci last big merger expect step end march succeed compani presid jeffrey gennett sinc recess shopper grown accustom hunt bargain pay full price discount store outlet mall flourish tradit store compel respond trim price cut margin depart store hit especi hard particularli shopper migrat away mall emerg analyst say virtual race bottom particularli difficult maci born seri merger past two decad made juggernaut industri stalwart middl tier retail compani neither advantag retail like hm store addit maci face increasingli fierc competit onlin site like amazon elsewher maci troubl drawn attent promin activist hedg fund starboard valu urg compani gener cash sell real estat beneath store starboard held percent maci share sept previous estim valu land billion friday analyst citigroup estim maci hold could worth least billion maci market valu comparison billion friday morn maci taken step sell redevelop store last year ad expert real estat transact board compani larg resist ambiti effort divest real estat includ deal compani sell underli land beneath store rent back compani suitor hudson bay compani far smaller market valu billion canadian dollar billion known bold step hudson bay compani assembl grow empir includ hudson bay depart store chain lord taylor crown jewel sak governor execut chairman hudson bay compani richard baker shown littl fear use debt novemb compani borrow nearli billion sak flagship midtown manhattan spoken often retail need highlight valu real estat financ bid maci may trickier howev carri billion debt may mean hudson bay compani bring partner borrow real estat hold spokesman hudson bay compani declin comment talk report earlier wall street journal comment rumor specul repres maci said repres starboard valu respond request comment analyst said saw merit potenti combin particularli given maci oper woe mr baker expertis wring money real estat clear logic despit dispar cap maci hudson bay compani craig johnson presid custom growth partner research firm said note refer maci stock ticker symbol ad retail market chang faster abl keep whether flight mall migrat onlin'\n",
      " 'alex ansari nato russia hold parallel exercis balkan nato russia hold parallel exercis balkan press tv russia militari nato forc hold parallel militari exercis two neighbor balkan countri russian troop particip war game serbia nato conduct militari drill montenegro media report monday russian forc day militari exercis serbia name slavic brotherhood begin wednesday includ russian paratroop air forc staffer three transport plane unspecifi number troop serbia belaru russia defens ministri said five day nato drill montenegro start monday involv respond flood chemic attack involv unarm personnel seven nato countri partner state past serbia montenegro constitut republ socialist feder republ yugoslavia countri socialist republ tradit russian christian orthodox alli state union form serbia montenegro two becam independ state sinc split two balkan neighbor seem head differ direct strateg montenegro taken pro western stanc award nato offer join northern atlant allianc nato invit montenegro met strong opposit russia meanwhil montenegrin offici accus russia stage alleg coup octob toppl pro western govern nato access bid serbia nato partner held exercis western allianc larg one foreign troop equip particip soil'\n",
      " 'david swanson keep f aliv david swanson author activist journalist radio host nobel peac prize nomine director worldbeyondwar com campaign coordin rootsact org host talk nation radio talk nation radio vt radio syndic pacifica network show also air wtju charlottesvil va wcsx detroit mi kghi westport wa whu storr ct wprr grand rapid mi krfp lp moscow id kzgm cabool mo kmud garbervil ca wazu peoria il wxrd crown point geneva radio geneva ny kkrn round mountain ca kskq lp ashland wuow lp oneonta ny lie radio pinol ca wyap lp clay wv detour johnson citi tn wzrd chicago il weft champaign il wxpi pittsburgh pa wdrt viroqua wi verac onlin liberti justic radio shirley ithaca commun radio ithaca ny wmcb greenfield prx org kao fm olympia wa wusb fm stoni brook ny wool fm bellow fall vermont wslr lp sarasota florida also blog davidswanson org warisacrim org prolif author latest book war lie daybreak undo imperi presid form perfect union world outlaw war swanson hold master degre philosophi univers virginia work newspap report commun director job includ press secretari denni kucinich presidenti campaign media coordin intern labor commun associ three year commun coordin acorn associ commun organ reform read full complet biographi davidswanson org also visit book site war crime keep f aliv david swanson octob petit stop f go global david swanson imagin local busi town invent brand new tool intend almost magic effect thousand mile away howev tool kept use local becam area unsaf children children got near tool tend increas blood pressur increas stress hormon lower read skill poorer memori impair auditori speech percept impair academ perform us would find situat least littl concern unless new invent design murder lot peopl fine imagin new tool ruin neighborhood peopl safe live near imagin govern compens peopl kick live near locat tool think might find troubl mass murder mission imagin also tool fairli frequent explod emit highli toxic chemic particl fiber unsaf breath air mile around normal problem tool need kill lot peopl work flaw new gadget expect cost least year money taken away numer expens benefici economi world trillion drain economi caus loss job radic diminuit resourc educ healthcar hous environment protect humanitarian aid worri case mean case abil kill ton human be stake product even work perfectli lead destroy earth natur environ high tech toy even design expect even abl design amazingli even shortcom matter long intent massiv murder destruct forgiven tool describ call f rootsact org find new petit launch local mind peopl act global place f intend base also link find explan tool decrib f petit direct unit state congress govern australia itali netherland norway turkey unit kingdom israel japan south korea world peopl burlington vermont fairbank alaska f base effort initi vermont stop f coalit save sky vermont western main matter alaska peac center univers alaska fairbank peac club north star chapter veteran peac world beyond war rootsact org code pink ben cohen petit read f weapon offens war serv defens purpos plan cost u trillion year starvat earth could end billion lack clean drink water billion per year first foremost wast resourc airplan kill militari spend contrari popular misconcept also hurt u economi see economi f caus neg health impact cognit impair children live near base render hous near airport unsuit residenti use high crash rate horribl consequ live area crash emiss major environment pollut war endang unit state particip nation rather protect nonviol tool law diplomaci aid crisi prevent verifi nuclear disarma substitut continu counterproduct war therefor undersign call immedi cancel f program whole immedi cancel plan base danger noisi jet near popul area oppos replac f weapon base f locat demand redirect money f back taxpay pocket environment human need u f custom nation around world includ fight climat chang pay student debt rebuild crumbl infrastructur improv educ healthcar hous add name david swanson author activist journalist radio host director worldbeyondwar org campaign coordin rootsact org swanson book includ war lie blog davidswanson org warisacrim org host talk nation radio nobel peac prize nomine follow twitter davidcnswanson facebook help support davidswanson org warisacrim org talknationradio org click http davidswanson org donat']\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cb0b5ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62a3aa92",
    "outputId": "a0b48f6a-828c-44f8-fdba-21172418acf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75d3b2",
   "metadata": {
    "id": "f92318e7"
   },
   "source": [
    "TF-IDF (Term Frequency, Inverse Document Frequency)\n",
    "\n",
    "### Converting Textual data to Numerical data\n",
    "\n",
    "* The TF-IDF Vectorizer\n",
    "* TF-IDF Vectorizer coverts textual data to numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b4176",
   "metadata": {
    "id": "51cc3ef1"
   },
   "source": [
    "Thsi is still a bit messed up and need to be cleaned, I stidued the HEROKYU app fiel and the vectorizer is use dto translate the input text to ML to do teh comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d004944",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "0543b31e",
    "outputId": "f81bb5a9-d380-4a84-9d7a-6e3c892a42bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e0a0705",
   "metadata": {
    "id": "f923e533"
   },
   "outputs": [],
   "source": [
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04e5a306",
   "metadata": {
    "id": "YZO9QQZoD8_r"
   },
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open('../Pickles/tfidfvect2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce95a43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer()\n"
     ]
    }
   ],
   "source": [
    "TEST_model = pickle.load(open('../Pickles/tfidfvect2.pkl', 'rb'))\n",
    "\n",
    "print(TEST_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf7806bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95438d19",
    "outputId": "190f59a3-8ed5-481e-8ad0-de3cd3baaadd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 109752)\t0.049158312425168854\n",
      "  (0, 109697)\t0.0190646711515277\n",
      "  (0, 108742)\t0.04416544119908134\n",
      "  (0, 108738)\t0.09477494042884232\n",
      "  (0, 108695)\t0.03758488097939004\n",
      "  (0, 108658)\t0.01130614774071694\n",
      "  (0, 108007)\t0.017092546683505856\n",
      "  (0, 107190)\t0.017105936674103112\n",
      "  (0, 107099)\t0.012543234221230963\n",
      "  (0, 107013)\t0.029126417104928328\n",
      "  (0, 106934)\t0.012863319680563097\n",
      "  (0, 106734)\t0.011771716334271506\n",
      "  (0, 105884)\t0.025727197929110487\n",
      "  (0, 105848)\t0.031296701378124764\n",
      "  (0, 104837)\t0.02153649554212262\n",
      "  (0, 103422)\t0.06544555398259812\n",
      "  (0, 102736)\t0.03314918847150756\n",
      "  (0, 102485)\t0.01639612818098454\n",
      "  (0, 101717)\t0.038071924979380216\n",
      "  (0, 101077)\t0.011082403436475742\n",
      "  (0, 101067)\t0.0432044670628921\n",
      "  (0, 101014)\t0.13602128375819167\n",
      "  (0, 100866)\t0.0713092337063475\n",
      "  (0, 99577)\t0.03944988916619374\n",
      "  (0, 99009)\t0.027120358929731154\n",
      "  :\t:\n",
      "  (20799, 7470)\t0.010635431711878486\n",
      "  (20799, 7143)\t0.02816704434978389\n",
      "  (20799, 6848)\t0.03959171777516513\n",
      "  (20799, 6810)\t0.025365585564187044\n",
      "  (20799, 6530)\t0.0423980387875893\n",
      "  (20799, 6084)\t0.0315457284306667\n",
      "  (20799, 5872)\t0.04632206994759717\n",
      "  (20799, 5517)\t0.024097152410748182\n",
      "  (20799, 5242)\t0.045417670739832466\n",
      "  (20799, 3271)\t0.03446674804290047\n",
      "  (20799, 3042)\t0.05007515404726805\n",
      "  (20799, 2955)\t0.015323407277242013\n",
      "  (20799, 2713)\t0.047800235719237465\n",
      "  (20799, 2294)\t0.08924712342400702\n",
      "  (20799, 1997)\t0.023153895918351708\n",
      "  (20799, 1995)\t0.029380105887880807\n",
      "  (20799, 1952)\t0.03330998179427733\n",
      "  (20799, 1886)\t0.033768770862532556\n",
      "  (20799, 1027)\t0.01893705656098481\n",
      "  (20799, 903)\t0.038248338479231606\n",
      "  (20799, 873)\t0.013807510861685218\n",
      "  (20799, 815)\t0.041753611202768166\n",
      "  (20799, 559)\t0.024511273226368112\n",
      "  (20799, 323)\t0.015366447869656087\n",
      "  (20799, 305)\t0.019031597510308154\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b35a4a4",
   "metadata": {
    "id": "0f84ef5f"
   },
   "source": [
    "Modeling & Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b30fa",
   "metadata": {
    "id": "7a246d29"
   },
   "source": [
    "### Splitting the data into test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46151891",
   "metadata": {
    "id": "6007c5c2"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.18, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804762c0",
   "metadata": {
    "id": "b653caf9"
   },
   "source": [
    "We use 2 models to determine the accuracy of teh training set and will then select the most accurate model to us ein HEREKO\n",
    "The first Model - Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2953d86a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "1915d04c",
    "outputId": "e7d71995-1315-4f1a-9f58-68e38565346e",
    "tags": [
     "history"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "logisticreg_model = LogisticRegression()\n",
    "\n",
    "logisticreg_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_dict = history.history\n",
    "# history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e7c25",
   "metadata": {
    "id": "0a019bc4"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98872c4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "304118ab",
    "outputId": "99ce9aec-a7b9-41f4-eefb-bf84c5d7a992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training data:  0.9790103189493433\n",
      "Accuracy score on the test data:  0.9564636752136753\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Score on Training Data\n",
    "X_train_prediction = logisticreg_model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
    "\n",
    "print('Accuracy score on the training data: ',training_data_accuracy)\n",
    "\n",
    "# Accuracy Score on Test Data\n",
    "X_test_prediction = logisticreg_model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
    "\n",
    "print('Accuracy score on the test data: ',test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43f85195",
   "metadata": {
    "id": "e2b32a09"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(logisticreg_model, open('../Pickles/logisticreg_model.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7ded5a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "014c5ef3",
    "outputId": "82bed337-cd23-4c88-f9a5-e3acd47f23c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.96      0.95      0.96      1919\\n           1       0.95      0.96      0.96      1825\\n\\n    accuracy                           0.96      3744\\n   macro avg       0.96      0.96      0.96      3744\\nweighted avg       0.96      0.96      0.96      3744\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification report for test data\n",
    "classification_report(Y_test, X_test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ea110",
   "metadata": {
    "id": "b26ebf70"
   },
   "source": [
    "**CLASSIFICATION MODEL : PASSIVE AGGRESSIVE CLASSIFIER**\n",
    "\n",
    "* Passive Aggressive Classifier works by responding as passive for correct classifications and responding as aggressive for any miscalculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56a14614",
   "metadata": {
    "id": "d486f0ca"
   },
   "outputs": [],
   "source": [
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dea76e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56733ec1",
    "outputId": "08614de7-b7e0-4a26-8bcf-6c60c62a2b80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy : 96.70745920745921 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing modules\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting dataset into train and test sets\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Creating model\n",
    "passiveagressive_model = PassiveAggressiveClassifier(C = 0.5, random_state = 5)\n",
    "\n",
    "# Fitting model\n",
    "passiveagressive_model.fit(X2_train, Y2_train)\n",
    "\n",
    "# Making prediction on test set\n",
    "test_pred = passiveagressive_model.predict(X2_test)\n",
    "\n",
    "# Model evaluation\n",
    "print(f\"Test Set Accuracy : {accuracy_score(Y2_test, test_pred) * 100} %\\n\\n\")\n",
    "\n",
    "#print(f\"Classification Report : \\n\\n{classification_report(Y2_test, test_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30aad454",
   "metadata": {
    "id": "cfd09b49"
   },
   "outputs": [],
   "source": [
    "pickle.dump(passiveagressive_model, open('../Pickles/passiveagressive_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4217aa3c",
   "metadata": {
    "id": "0eb9e924"
   },
   "source": [
    "Testing the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "89bda029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 95.65%\n",
      "Prediction for example 500:  1\n",
      "Johan Says it is a porky:)\n"
     ]
    }
   ],
   "source": [
    "y_pred = logisticreg_model.predict(X_test)\n",
    "\n",
    "# Calculate the prediction accuracy\n",
    "accuracy = np.mean(y_pred == Y_test) * 100\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Prediction accuracy: {:.2f}%\".format(accuracy))\n",
    "\n",
    "# Print the prediction for a single example\n",
    "X_new = X_test[501]\n",
    "prediction = logisticreg_model.predict(X_new.reshape(1, -1))\n",
    "print(\"Prediction for example 500: \", prediction[0])\n",
    "if (prediction[0] == 0):\n",
    "  print('Jono says its True')\n",
    "else:\n",
    "  print('Johan Says it is a porky:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee542d9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f35d01a",
    "outputId": "87003203-58d1-468f-febd-08cb3f9497a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 96.46%\n",
      "Prediction for example 500:  1\n",
      "Johan Says it is a porky:)\n"
     ]
    }
   ],
   "source": [
    "y2_pred = logisticreg_model.predict(X2_test)\n",
    "\n",
    "# Calculate the prediction accuracy\n",
    "accuracy = np.mean(y2_pred == Y2_test) * 100\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Prediction accuracy: {:.2f}%\".format(accuracy))\n",
    "\n",
    "# Print the prediction for a single example\n",
    "X2_new = X2_test[501]\n",
    "prediction2 = prediction2 = passiveagressive_model.predict(X2_new.reshape(1, -1))\n",
    "print(\"Prediction for example 500: \", prediction[0])\n",
    "if (prediction[0] == 0):\n",
    "  print('Jono says its True')\n",
    "else:\n",
    "  print('Johan Says it is a porky:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ded013bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "53216c3b",
    "outputId": "b3ddee1f-8b8d-4c16-b4bd-05d12eabacd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>Technocracy: The Real Reason Why The UN Wants ...</td>\n",
       "      <td>Activist Post</td>\n",
       "      <td>By Patrick Wood By its very nature, the Intern...</td>\n",
       "      <td>1</td>\n",
       "      <td>activist post technocraci real reason un want ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title         author  \\\n",
       "100  100  Technocracy: The Real Reason Why The UN Wants ...  Activist Post   \n",
       "\n",
       "                                                  text  label  \\\n",
       "100  By Patrick Wood By its very nature, the Intern...      1   \n",
       "\n",
       "                                           text_corpus  \n",
       "100  activist post technocraci real reason un want ...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset[100:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2fbeec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e7f51b5",
    "outputId": "5c86dc3f-cc8f-45a5-961a-7172d3859859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b955a095",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94efd9e9",
    "outputId": "76ebbc05-2ab7-4016-bd29-a358456aab11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Johan Says it is a porky:)\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[301]\n",
    "\n",
    "prediction = logisticreg_model.predict(X_new)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "  print('Jono says its True')\n",
    "else:\n",
    "  print('Johan Says it is a porky:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c753f79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c9261cf",
    "outputId": "54f1a90e-b597-4823-b1ac-95ccd39eb9e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[301])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee81e358",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "0c6b5a46",
    "outputId": "66f30668-2fac-47d4-a137-34e61c44b8d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>300</td>\n",
       "      <td>M.T.A. Shortens L Train Shutdown to 15 Months ...</td>\n",
       "      <td>Emma G. Fitzsimmons</td>\n",
       "      <td>The Metropolitan Transportation Authority had ...</td>\n",
       "      <td>0</td>\n",
       "      <td>emma g fitzsimmon shorten l train shutdown mon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "300  300  M.T.A. Shortens L Train Shutdown to 15 Months ...   \n",
       "\n",
       "                  author                                               text  \\\n",
       "300  Emma G. Fitzsimmons  The Metropolitan Transportation Authority had ...   \n",
       "\n",
       "     label                                        text_corpus  \n",
       "300      0  emma g fitzsimmon shorten l train shutdown mon...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset[300:301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "532a39b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_136216\\3119347509.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2051\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2052\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2053\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2054\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m         \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1202\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \"\"\"\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71729407",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96a37b98",
    "outputId": "c624e03a-b09b-4801-e8c6-7bd1ca6109a1"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_136216\\3424270250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpickled_model1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logisticreg_model.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpickled_model1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2051\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2052\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2053\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2054\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m         \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1202\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \"\"\"\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "pickled_model1 = pickle.load(open('logisticreg_model.pkl', 'rb'))\n",
    "pickled_model1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a95d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ab2357c",
    "outputId": "8151f4d9-d005-4d08-c4f7-fdace7e0da51"
   },
   "outputs": [],
   "source": [
    "pickled_model2 = pickle.load(open('passiveagressive_model.pkl', 'rb'))\n",
    "pickled_model2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e0161",
   "metadata": {
    "id": "170922ea"
   },
   "source": [
    "FAngo tested a point to clarify teh vector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8ed22",
   "metadata": {
    "id": "b0287aa5"
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85837835",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "8144960d",
    "outputId": "4b1c42c4-0e78-4936-a1df-b47753a34daa"
   },
   "outputs": [],
   "source": [
    "review = re.sub('[^a-zA-Z]', ' ', news_dataset['text_corpus'][100])\n",
    "review = review.lower()\n",
    "review = review.split()\n",
    "    \n",
    "review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "review = ' '.join(review)\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c9936d",
   "metadata": {
    "id": "79886864"
   },
   "outputs": [],
   "source": [
    "val = vectorizer.transform([review]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b0a25",
   "metadata": {
    "id": "884b6a48"
   },
   "outputs": [],
   "source": [
    "tfidfvect2_model2 = pickle.load(open('tfidfvect2.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2956a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880908d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2140.826204,
   "end_time": "2021-09-29T17:10:10.602486",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-29T16:34:29.776282",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
