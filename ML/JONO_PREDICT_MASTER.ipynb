{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24755160",
   "metadata": {
    "id": "8c9cb573"
   },
   "source": [
    "This code reads in two CSV files named 'test.csv' and 'train.csv', cleans the data by filling in missing values with empty strings, creates a new column in the training dataframe called 'text_corpus' by concatenating the 'author', 'title', and 'text' columns, and then creates several dataframes for different columns in the training dataframe. It also creates a date table for article dates and loads all the dataframes into a PostgreSQL database using SQLAlchemy.\n",
    "\n",
    "After loading the data into the database, it uses pd.read_sql_query() to query the database and display the first 15 rows of each table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca5946",
   "metadata": {
    "id": "4d5dda4c"
   },
   "source": [
    "#### Dataset used - https://www.kaggle.com/fake-news/data\n",
    "\n",
    "### Dataset Description\n",
    "\n",
    "train.csv: A full training dataset with the following attributes:\n",
    "\n",
    "* id: unique id for a news article\n",
    "* title: the title of a news article\n",
    "* author: author of the news article\n",
    "* text: the text of the article; could be incomplete\n",
    "* label: a label that marks the article as potentially unreliable\n",
    "  * 1: FAKE\n",
    "  * 0: TRUE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9612db7e",
   "metadata": {
    "id": "f47d9fde"
   },
   "source": [
    "Ensure the file creator is installed to save the MODELS for use in Heroku app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc05c85b",
   "metadata": {
    "id": "acdf7db5"
   },
   "source": [
    "Set the dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "643aaced",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/jonowood/Project-4-A-Team/blob/JonBranch/ML/JONO_PREDICT_MASTER.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/jonowood/Project-4-A-Team/blob/JonBranch/ML/JONO_PREDICT_MASTER.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" /> Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f313070",
   "metadata": {
    "id": "7b4b4979"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "from api_keys import postgres_p\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b19d1d8",
   "metadata": {
    "id": "5cbd1c06"
   },
   "source": [
    "The Natural Language Toolkit (NLTK) is a platform used for building Python programs that work with human language data for applying in statistical natural language processing (NLP). It contains text processing libraries for tokenization, parsing, classification, stemming, tagging and semantic reasoning.\n",
    "The nltk.corpus package defines a collection of corpus reader classes, which can be used to access the contents of a diverse set of corpora. The list of available corpora is given at: https://www.nltk.org/nltk_data/ Each corpus reader class is specialized to handle a specific corpus forma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a94e780",
   "metadata": {
    "id": "c32358ea"
   },
   "source": [
    "Load and test all the STW ,Stopwords are words which occur frequently in a corpus. e.g a, an, the, in. Frequently occurring words are removed from the corpus for the purpose of text-normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c392dc4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b3d25c8",
    "outputId": "a174a4ae-f59d-4210-e4b1-32f29afa4c50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jonow\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc9173f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd8da98b",
    "outputId": "2a30bc0b-3d38-431f-dc5a-1be22dfd8839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# check if Stopwords laoded in english\n",
    "\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67432b17",
   "metadata": {
    "id": "a44f0a84"
   },
   "source": [
    "Data Pre-processing and Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1cb37a",
   "metadata": {
    "id": "83fffc5d"
   },
   "source": [
    "Regular Expression Syntax. A regular expression (or RE) specifies a set of strings that matches it; the functions in this module let you check if a particular string matches a given regular expression (or if a given regular expression matches a particular string, which comes down to the same thing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b626a97",
   "metadata": {},
   "source": [
    "# insert SQL here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1ea1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(database=\"Project_4\", user=\"postgres\", password=postgres_p) #host=\"your_host_address\", port=\"your_port_number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b838505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL query to retrieve the data\n",
    "query = \"SELECT a.article_id, a.article_label, t.text_corpus FROM article_id a  JOIN text_corpus t ON a.article_id = t.article_id LIMIT 100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edd6955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query and store the results in a Pandas DataFrame\n",
    "news_dataset = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca1ffc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd99892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_label</th>\n",
       "      <th>text_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Darrell Lucus House Dem Aide: We Didn’t Even S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Consortiumnews.com Why the Truth Might Get You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Jessica Purkiss 15 Civilians Killed In Single ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Howard Portnoy Iranian woman jailed for fictio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>Jacey Fortin Dress Like a Woman? What Does Tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>Brett Anderson At 91, Ella Brennan Still Feeds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>Jane Perlez Pressing Asia Agenda, Obama Treads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>Josh Katz Democrats Have a 60 Percent Chance t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>News: PR Disaster: The President Of Panasonic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id  article_label  \\\n",
       "0            0              1   \n",
       "1            1              0   \n",
       "2            2              1   \n",
       "3            3              1   \n",
       "4            4              1   \n",
       "..         ...            ...   \n",
       "95          72              0   \n",
       "96          73              0   \n",
       "97          74              0   \n",
       "98          75              0   \n",
       "99          76              1   \n",
       "\n",
       "                                          text_corpus  \n",
       "0   Darrell Lucus House Dem Aide: We Didn’t Even S...  \n",
       "1   Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...  \n",
       "2   Consortiumnews.com Why the Truth Might Get You...  \n",
       "3   Jessica Purkiss 15 Civilians Killed In Single ...  \n",
       "4   Howard Portnoy Iranian woman jailed for fictio...  \n",
       "..                                                ...  \n",
       "95  Jacey Fortin Dress Like a Woman? What Does Tha...  \n",
       "96  Brett Anderson At 91, Ella Brennan Still Feeds...  \n",
       "97  Jane Perlez Pressing Asia Agenda, Obama Treads...  \n",
       "98  Josh Katz Democrats Have a 60 Percent Chance t...  \n",
       "99   News: PR Disaster: The President Of Panasonic...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d214d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will separate the data and label i.e. text_corpus and label fields\n",
    "X = news_dataset['text_corpus']\n",
    "Y = news_dataset['article_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d98a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for stemming the content\n",
    "port_stem = PorterStemmer()\n",
    "def stemming(content):\n",
    "    # Pick all alphabet characters - lowercase and uppercase...all others such as numbers and punctuations will be removed. Numbers or punctuations will be replaced by a whitespace\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
    "    # Converting all letters to lowercase \n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    # Converting all to a splitted case or a list\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    # Applying stemming, so we get the root words wherever possible + remove stopwords as well\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    # Join all the words in final content\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a6c0866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply stemming to the text_corpus column\n",
    "X = X.apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e878d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24529202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     darrel lucu hous dem aid even see comey letter...\n",
      "1     daniel j flynn flynn hillari clinton big woman...\n",
      "2     consortiumnew com truth might get fire truth m...\n",
      "3     jessica purkiss civilian kill singl us airstri...\n",
      "4     howard portnoy iranian woman jail fiction unpu...\n",
      "                            ...                        \n",
      "95    jacey fortin dress like woman mean new york ti...\n",
      "96    brett anderson ella brennan still feed lead ne...\n",
      "97    jane perlez press asia agenda obama tread ligh...\n",
      "98    josh katz democrat percent chanc retak senat n...\n",
      "99    news pr disast presid panason forc resign pana...\n",
      "Name: text_corpus, Length: 100, dtype: object\n",
      "0     1\n",
      "1     0\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "     ..\n",
      "95    0\n",
      "96    0\n",
      "97    0\n",
      "98    0\n",
      "99    1\n",
      "Name: article_label, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the X and Y variables\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75d3b2",
   "metadata": {
    "id": "f92318e7"
   },
   "source": [
    "TF-IDF (Term Frequency, Inverse Document Frequency)\n",
    "\n",
    "### Converting Textual data to Numerical data\n",
    "\n",
    "* The TF-IDF Vectorizer\n",
    "* TF-IDF Vectorizer coverts textual data to numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b4176",
   "metadata": {
    "id": "51cc3ef1"
   },
   "source": [
    "Thsi is still a bit messed up and need to be cleaned, I stidued the HEROKYU app fiel and the vectorizer is use dto translate the input text to ML to do teh comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d004944",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "0543b31e",
    "outputId": "f81bb5a9-d380-4a84-9d7a-6e3c892a42bc"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "\n",
    "X_transformed = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04e5a306",
   "metadata": {
    "id": "YZO9QQZoD8_r"
   },
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open('../Pickles/tfidfvect2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce95a43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer()\n"
     ]
    }
   ],
   "source": [
    "TEST_model = pickle.load(open('../Pickles/tfidfvect2.pkl', 'rb'))\n",
    "\n",
    "print(TEST_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf7806bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95438d19",
    "outputId": "190f59a3-8ed5-481e-8ad0-de3cd3baaadd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8093)\t0.03694408830646858\n",
      "  (0, 8089)\t0.021628144918573823\n",
      "  (0, 8050)\t0.0497274539521895\n",
      "  (0, 8049)\t0.11016364582333155\n",
      "  (0, 8042)\t0.04022767162925188\n",
      "  (0, 8035)\t0.013089773516581497\n",
      "  (0, 7986)\t0.017691705351612422\n",
      "  (0, 7934)\t0.01861195231446561\n",
      "  (0, 7931)\t0.015043445572472646\n",
      "  (0, 7925)\t0.03694408830646858\n",
      "  (0, 7919)\t0.01374287660665248\n",
      "  (0, 7901)\t0.013089773516581497\n",
      "  (0, 7846)\t0.025654557793032627\n",
      "  (0, 7844)\t0.03597218816753848\n",
      "  (0, 7768)\t0.026538631430371946\n",
      "  (0, 7694)\t0.06780137453754952\n",
      "  (0, 7636)\t0.03006645541414307\n",
      "  (0, 7613)\t0.018945605044700796\n",
      "  (0, 7530)\t0.03390068726877476\n",
      "  (0, 7501)\t0.01278336564572092\n",
      "  (0, 7500)\t0.05487750586388943\n",
      "  (0, 7492)\t0.15392734675819578\n",
      "  (0, 7486)\t0.08993047041884619\n",
      "  (0, 7398)\t0.03694408830646858\n",
      "  (0, 7348)\t0.026538631430371946\n",
      "  :\t:\n",
      "  (99, 1600)\t0.04946733759450423\n",
      "  (99, 1581)\t0.042484792480827906\n",
      "  (99, 1507)\t0.03625065040130079\n",
      "  (99, 1476)\t0.033199456795716224\n",
      "  (99, 1446)\t0.02629924016155174\n",
      "  (99, 1441)\t0.038916124026496406\n",
      "  (99, 1432)\t0.13632049356928438\n",
      "  (99, 1349)\t0.042484792480827906\n",
      "  (99, 1279)\t0.040551066254828266\n",
      "  (99, 1278)\t0.03749987264924371\n",
      "  (99, 1272)\t0.03156451456738437\n",
      "  (99, 1202)\t0.029505270539074865\n",
      "  (99, 1112)\t0.033199456795716224\n",
      "  (99, 934)\t0.03625065040130079\n",
      "  (99, 923)\t0.026770701356742563\n",
      "  (99, 660)\t0.02889904094218874\n",
      "  (99, 651)\t0.022153661079962823\n",
      "  (99, 557)\t0.04033614206348971\n",
      "  (99, 538)\t0.024212905108272325\n",
      "  (99, 433)\t0.15660927470240338\n",
      "  (99, 356)\t0.040551066254828266\n",
      "  (99, 294)\t0.042484792480827906\n",
      "  (99, 133)\t0.052203091567467795\n",
      "  (99, 98)\t0.038916124026496406\n",
      "  (99, 24)\t0.04485148210835575\n"
     ]
    }
   ],
   "source": [
    "print(X_transformed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56089711",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b35a4a4",
   "metadata": {
    "id": "0f84ef5f"
   },
   "source": [
    "Modeling & Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b30fa",
   "metadata": {
    "id": "7a246d29"
   },
   "source": [
    "### Splitting the data into test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46151891",
   "metadata": {
    "id": "6007c5c2"
   },
   "outputs": [],
   "source": [
    "# Splitting the data into test and train datasets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_transformed, Y, test_size=0.18, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804762c0",
   "metadata": {
    "id": "b653caf9"
   },
   "source": [
    "We use 2 models to determine the accuracy of teh training set and will then select the most accurate model to us ein HEREKO\n",
    "The first Model - Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2953d86a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "1915d04c",
    "outputId": "e7d71995-1315-4f1a-9f58-68e38565346e",
    "tags": [
     "history"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "logisticreg_model = LogisticRegression()\n",
    "\n",
    "logisticreg_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e7c25",
   "metadata": {
    "id": "0a019bc4"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98872c4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "304118ab",
    "outputId": "99ce9aec-a7b9-41f4-eefb-bf84c5d7a992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training data:  1.0\n",
      "Accuracy score on the test data:  0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Score on Training Data\n",
    "X_train_prediction = logisticreg_model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
    "\n",
    "print('Accuracy score on the training data: ',training_data_accuracy)\n",
    "\n",
    "# Accuracy Score on Test Data\n",
    "X_test_prediction = logisticreg_model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
    "\n",
    "print('Accuracy score on the test data: ',test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43f85195",
   "metadata": {
    "id": "e2b32a09"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(logisticreg_model, open('../Pickles/logisticreg_model.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7ded5a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "014c5ef3",
    "outputId": "82bed337-cd23-4c88-f9a5-e3acd47f23c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.88      0.64      0.74        11\\n           1       0.60      0.86      0.71         7\\n\\n    accuracy                           0.72        18\\n   macro avg       0.74      0.75      0.72        18\\nweighted avg       0.77      0.72      0.72        18\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification report for test data\n",
    "classification_report(Y_test, X_test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ea110",
   "metadata": {
    "id": "b26ebf70"
   },
   "source": [
    "**CLASSIFICATION MODEL : PASSIVE AGGRESSIVE CLASSIFIER**\n",
    "\n",
    "* Passive Aggressive Classifier works by responding as passive for correct classifications and responding as aggressive for any miscalculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56a14614",
   "metadata": {
    "id": "d486f0ca"
   },
   "outputs": [],
   "source": [
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X_transformed, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "30aad454",
   "metadata": {
    "id": "cfd09b49"
   },
   "outputs": [],
   "source": [
    "pickle.dump(passiveagressive_model, open('../Pickles/passiveagressive_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4217aa3c",
   "metadata": {
    "id": "0eb9e924"
   },
   "source": [
    "Testing the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72bf0a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy : 69.6969696969697 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing modules\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create the vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the input data\n",
    "X_transformed = vectorizer.fit_transform(X)\n",
    "\n",
    "# Splitting dataset into train and test sets\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X_transformed, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Creating model\n",
    "passiveagressive_model = PassiveAggressiveClassifier(C=0.5, random_state=5)\n",
    "\n",
    "# Fitting model\n",
    "passiveagressive_model.fit(X2_train, Y2_train)\n",
    "\n",
    "# Making prediction on test set\n",
    "test_pred = passiveagressive_model.predict(X2_test)\n",
    "\n",
    "# Model evaluation\n",
    "print(f\"Test Set Accuracy : {accuracy_score(Y2_test, test_pred) * 100} %\\n\\n\")\n",
    "\n",
    "# Save the vectorizer\n",
    "pickle.dump(vectorizer, open('../Pickles/tfidf_vectorizer.pkl', 'wb'))\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(passiveagressive_model, open('../Pickles/passiveagressive_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89bda029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 72.22%\n",
      "Prediction for example 500:  0\n",
      "Jono says its True\n"
     ]
    }
   ],
   "source": [
    "y_pred = logisticreg_model.predict(X_test)\n",
    "\n",
    "# Calculate the prediction accuracy\n",
    "accuracy = np.mean(y_pred == Y_test) * 100\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Prediction accuracy: {:.2f}%\".format(accuracy))\n",
    "\n",
    "# Print the prediction for a single example\n",
    "X_new = X_test[5]\n",
    "prediction = logisticreg_model.predict(X_new.reshape(1, -1))\n",
    "print(\"Prediction for example 500: \", prediction[0])\n",
    "if (prediction[0] == 0):\n",
    "  print('Jono says its True')\n",
    "else:\n",
    "  print('Johan Says it is a porky:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee542d9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f35d01a",
    "outputId": "87003203-58d1-468f-febd-08cb3f9497a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 84.85%\n",
      "Prediction for example 500:  0\n",
      "Jono says its True\n"
     ]
    }
   ],
   "source": [
    "y2_pred = logisticreg_model.predict(X2_test)\n",
    "\n",
    "# Calculate the prediction accuracy\n",
    "accuracy = np.mean(y2_pred == Y2_test) * 100\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Prediction accuracy: {:.2f}%\".format(accuracy))\n",
    "\n",
    "# Print the prediction for a single example\n",
    "X2_new = X2_test[5]\n",
    "prediction2 = passiveagressive_model.predict(X2_new.reshape(1, -1))\n",
    "print(\"Prediction for example 500: \", prediction[0])\n",
    "if (prediction[0] == 0):\n",
    "  print('Jono says its True')\n",
    "else:\n",
    "  print('Johan Says it is a porky:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ded013bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "53216c3b",
    "outputId": "b3ddee1f-8b8d-4c16-b4bd-05d12eabacd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_label</th>\n",
       "      <th>text_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Aaron Klein Obama’s Organizing for Action Part...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id  article_label  \\\n",
       "10          10              0   \n",
       "\n",
       "                                          text_corpus  \n",
       "10  Aaron Klein Obama’s Organizing for Action Part...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset[10:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f2fbeec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e7f51b5",
    "outputId": "5c86dc3f-cc8f-45a5-961a-7172d3859859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83    1\n",
      "53    0\n",
      "70    0\n",
      "45    0\n",
      "44    0\n",
      "39    0\n",
      "22    1\n",
      "80    0\n",
      "10    0\n",
      "0     1\n",
      "18    1\n",
      "30    0\n",
      "73    1\n",
      "33    0\n",
      "90    0\n",
      "4     1\n",
      "76    1\n",
      "77    0\n",
      "Name: article_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b955a095",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94efd9e9",
    "outputId": "76ebbc05-2ab7-4016-bd29-a358456aab11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Johan Says it is a porky:)\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[3]\n",
    "\n",
    "prediction = logisticreg_model.predict(X_new)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "  print('Jono says its True')\n",
    "else:\n",
    "  print('Johan Says it is a porky:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c753f79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c9261cf",
    "outputId": "54f1a90e-b597-4823-b1ac-95ccd39eb9e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83    1\n",
      "53    0\n",
      "70    0\n",
      "45    0\n",
      "44    0\n",
      "39    0\n",
      "22    1\n",
      "80    0\n",
      "10    0\n",
      "0     1\n",
      "18    1\n",
      "30    0\n",
      "73    1\n",
      "33    0\n",
      "90    0\n",
      "4     1\n",
      "76    1\n",
      "77    0\n",
      "Name: article_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ee81e358",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "0c6b5a46",
    "outputId": "66f30668-2fac-47d4-a137-34e61c44b8d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_label</th>\n",
       "      <th>text_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [article_id, article_label, text_corpus]\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset[300:301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "532a39b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     darrel lucu hous dem aid even see comey letter...\n",
      "1     daniel j flynn flynn hillari clinton big woman...\n",
      "2     consortiumnew com truth might get fire truth m...\n",
      "3     jessica purkiss civilian kill singl us airstri...\n",
      "4     howard portnoy iranian woman jail fiction unpu...\n",
      "                            ...                        \n",
      "95    jacey fortin dress like woman mean new york ti...\n",
      "96    brett anderson ella brennan still feed lead ne...\n",
      "97    jane perlez press asia agenda obama tread ligh...\n",
      "98    josh katz democrat percent chanc retak senat n...\n",
      "99    news pr disast presid panason forc resign pana...\n",
      "Name: text_corpus, Length: 100, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X)\n",
    "vectorizer.fit(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1510cecb",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!######################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7a1faa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer()\n",
    "# vectorizer.fit(X)\n",
    "\n",
    "vectorizer = pickle.load(open('../Pickles/tfidfvect2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "839febd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X is an array of text inputs\n",
    "X_preprocessed = [stemming(text) for text in X]  # Apply stemming to each text in the array\n",
    "X_vectorized = vectorizer.transform(X_preprocessed)  # Convert to numerical format using the trained vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "71729407",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96a37b98",
    "outputId": "c624e03a-b09b-4801-e8c6-7bd1ca6109a1"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 8134 features, but LogisticRegression is expecting 52004 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_120924\\1857110878.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpickled_model1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logisticreg_model.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickled_model1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_vectorized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \"\"\"\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m             raise ValueError(\n\u001b[1;32m--> 401\u001b[1;33m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 8134 features, but LogisticRegression is expecting 52004 features as input."
     ]
    }
   ],
   "source": [
    "pickled_model1 = pickle.load(open('logisticreg_model.pkl', 'rb'))\n",
    "predictions = pickled_model1.predict(X_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2a95d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ab2357c",
    "outputId": "8151f4d9-d005-4d08-c4f7-fdace7e0da51"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 8134 features, but PassiveAggressiveClassifier is expecting 52004 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_120924\\2093752942.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpickled_model2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'passiveagressive_model.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpickled_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \"\"\"\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonow\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m             raise ValueError(\n\u001b[1;32m--> 401\u001b[1;33m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 8134 features, but PassiveAggressiveClassifier is expecting 52004 features as input."
     ]
    }
   ],
   "source": [
    "pickled_model2 = pickle.load(open('passiveagressive_model.pkl', 'rb'))\n",
    "pickled_model2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e0161",
   "metadata": {
    "id": "170922ea"
   },
   "source": [
    "FAngo tested a point to clarify teh vector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8ed22",
   "metadata": {
    "id": "b0287aa5"
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85837835",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "8144960d",
    "outputId": "4b1c42c4-0e78-4936-a1df-b47753a34daa"
   },
   "outputs": [],
   "source": [
    "review = re.sub('[^a-zA-Z]', ' ', news_dataset['text_corpus'][100])\n",
    "review = review.lower()\n",
    "review = review.split()\n",
    "    \n",
    "review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "review = ' '.join(review)\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c9936d",
   "metadata": {
    "id": "79886864"
   },
   "outputs": [],
   "source": [
    "val = vectorizer.transform([review]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b0a25",
   "metadata": {
    "id": "884b6a48"
   },
   "outputs": [],
   "source": [
    "tfidfvect2_model2 = pickle.load(open('tfidfvect2.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2956a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880908d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2140.826204,
   "end_time": "2021-09-29T17:10:10.602486",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-29T16:34:29.776282",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
