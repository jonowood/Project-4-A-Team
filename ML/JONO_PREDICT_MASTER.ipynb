{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24755160",
   "metadata": {
    "id": "8c9cb573"
   },
   "source": [
    "This code reads in two CSV files named 'test.csv' and 'train.csv', cleans the data by filling in missing values with empty strings, creates a new column in the training dataframe called 'text_corpus' by concatenating the 'author', 'title', and 'text' columns, and then creates several dataframes for different columns in the training dataframe. It also creates a date table for article dates and loads all the dataframes into a PostgreSQL database using SQLAlchemy.\n",
    "\n",
    "After loading the data into the database, it uses pd.read_sql_query() to query the database and display the first 15 rows of each table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca5946",
   "metadata": {
    "id": "4d5dda4c"
   },
   "source": [
    "#### Dataset used - https://www.kaggle.com/fake-news/data\n",
    "\n",
    "### Dataset Description\n",
    "\n",
    "train.csv: A full training dataset with the following attributes:\n",
    "\n",
    "* id: unique id for a news article\n",
    "* title: the title of a news article\n",
    "* author: author of the news article\n",
    "* text: the text of the article; could be incomplete\n",
    "* label: a label that marks the article as potentially unreliable\n",
    "  * 1: FAKE\n",
    "  * 0: TRUE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9612db7e",
   "metadata": {
    "id": "f47d9fde"
   },
   "source": [
    "Ensure the file creator is installed to save the MODELS for use in Heroku app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc05c85b",
   "metadata": {
    "id": "acdf7db5"
   },
   "source": [
    "Set the dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "643aaced",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/jonowood/Project-4-A-Team/blob/JonBranch/ML/JONO_PREDICT_MASTER.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/jonowood/Project-4-A-Team/blob/JonBranch/ML/JONO_PREDICT_MASTER.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" /> Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f313070",
   "metadata": {
    "id": "7b4b4979"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "from api_keys import postgres_p\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b19d1d8",
   "metadata": {
    "id": "5cbd1c06"
   },
   "source": [
    "The Natural Language Toolkit (NLTK) is a platform used for building Python programs that work with human language data for applying in statistical natural language processing (NLP). It contains text processing libraries for tokenization, parsing, classification, stemming, tagging and semantic reasoning.\n",
    "The nltk.corpus package defines a collection of corpus reader classes, which can be used to access the contents of a diverse set of corpora. The list of available corpora is given at: https://www.nltk.org/nltk_data/ Each corpus reader class is specialized to handle a specific corpus forma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a94e780",
   "metadata": {
    "id": "c32358ea"
   },
   "source": [
    "Load and test all the STW ,Stopwords are words which occur frequently in a corpus. e.g a, an, the, in. Frequently occurring words are removed from the corpus for the purpose of text-normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c392dc4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b3d25c8",
    "outputId": "a174a4ae-f59d-4210-e4b1-32f29afa4c50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jonow\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc9173f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd8da98b",
    "outputId": "2a30bc0b-3d38-431f-dc5a-1be22dfd8839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# check if Stopwords laoded in english\n",
    "\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67432b17",
   "metadata": {
    "id": "a44f0a84"
   },
   "source": [
    "Data Pre-processing and Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1cb37a",
   "metadata": {
    "id": "83fffc5d"
   },
   "source": [
    "Regular Expression Syntax. A regular expression (or RE) specifies a set of strings that matches it; the functions in this module let you check if a particular string matches a given regular expression (or if a given regular expression matches a particular string, which comes down to the same thing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b626a97",
   "metadata": {},
   "source": [
    "# insert SQL here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1ea1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(database=\"Project_4\", user=\"postgres\", password=postgres_p) #host=\"your_host_address\", port=\"your_port_number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b838505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL query to retrieve the data\n",
    "query = \"SELECT a.article_id, a.article_label, t.text_corpus FROM article_id a  JOIN text_corpus t ON a.article_id = t.article_id LIMIT 100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edd6955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query and store the results in a Pandas DataFrame\n",
    "news_dataset = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca1ffc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd99892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_label</th>\n",
       "      <th>text_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Darrell Lucus House Dem Aide: We Didn’t Even S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Consortiumnews.com Why the Truth Might Get You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Jessica Purkiss 15 Civilians Killed In Single ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Howard Portnoy Iranian woman jailed for fictio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>Jacey Fortin Dress Like a Woman? What Does Tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>Brett Anderson At 91, Ella Brennan Still Feeds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>Jane Perlez Pressing Asia Agenda, Obama Treads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>Josh Katz Democrats Have a 60 Percent Chance t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>News: PR Disaster: The President Of Panasonic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id  article_label  \\\n",
       "0            0              1   \n",
       "1            1              0   \n",
       "2            2              1   \n",
       "3            3              1   \n",
       "4            4              1   \n",
       "..         ...            ...   \n",
       "95          72              0   \n",
       "96          73              0   \n",
       "97          74              0   \n",
       "98          75              0   \n",
       "99          76              1   \n",
       "\n",
       "                                          text_corpus  \n",
       "0   Darrell Lucus House Dem Aide: We Didn’t Even S...  \n",
       "1   Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...  \n",
       "2   Consortiumnews.com Why the Truth Might Get You...  \n",
       "3   Jessica Purkiss 15 Civilians Killed In Single ...  \n",
       "4   Howard Portnoy Iranian woman jailed for fictio...  \n",
       "..                                                ...  \n",
       "95  Jacey Fortin Dress Like a Woman? What Does Tha...  \n",
       "96  Brett Anderson At 91, Ella Brennan Still Feeds...  \n",
       "97  Jane Perlez Pressing Asia Agenda, Obama Treads...  \n",
       "98  Josh Katz Democrats Have a 60 Percent Chance t...  \n",
       "99   News: PR Disaster: The President Of Panasonic...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d214d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will separate the data and label i.e. text_corpus and label fields\n",
    "X = news_dataset['text_corpus']\n",
    "Y = news_dataset['article_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d98a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for stemming the content\n",
    "port_stem = PorterStemmer()\n",
    "def stemming(content):\n",
    "    # Pick all alphabet characters - lowercase and uppercase...all others such as numbers and punctuations will be removed. Numbers or punctuations will be replaced by a whitespace\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
    "    # Converting all letters to lowercase \n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    # Converting all to a splitted case or a list\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    # Applying stemming, so we get the root words wherever possible + remove stopwords as well\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    # Join all the words in final content\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a6c0866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply stemming to the text_corpus column\n",
    "X = X.apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24529202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     darrel lucu hous dem aid even see comey letter...\n",
      "1     daniel j flynn flynn hillari clinton big woman...\n",
      "2     consortiumnew com truth might get fire truth m...\n",
      "3     jessica purkiss civilian kill singl us airstri...\n",
      "4     howard portnoy iranian woman jail fiction unpu...\n",
      "                            ...                        \n",
      "95    jacey fortin dress like woman mean new york ti...\n",
      "96    brett anderson ella brennan still feed lead ne...\n",
      "97    jane perlez press asia agenda obama tread ligh...\n",
      "98    josh katz democrat percent chanc retak senat n...\n",
      "99    news pr disast presid panason forc resign pana...\n",
      "Name: text_corpus, Length: 100, dtype: object\n",
      "0     1\n",
      "1     0\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "     ..\n",
      "95    0\n",
      "96    0\n",
      "97    0\n",
      "98    0\n",
      "99    1\n",
      "Name: article_label, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the X and Y variables\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75d3b2",
   "metadata": {
    "id": "f92318e7"
   },
   "source": [
    "TF-IDF (Term Frequency, Inverse Document Frequency)\n",
    "\n",
    "### Converting Textual data to Numerical data\n",
    "\n",
    "* The TF-IDF Vectorizer\n",
    "* TF-IDF Vectorizer coverts textual data to numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b4176",
   "metadata": {
    "id": "51cc3ef1"
   },
   "source": [
    "Thsi is still a bit messed up and need to be cleaned, I stidued the HEROKYU app fiel and the vectorizer is use dto translate the input text to ML to do teh comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d004944",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "0543b31e",
    "outputId": "f81bb5a9-d380-4a84-9d7a-6e3c892a42bc"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "\n",
    "X_transformed = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e5a306",
   "metadata": {
    "id": "YZO9QQZoD8_r"
   },
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open('../Pickles/tfidfvect2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce95a43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer()\n"
     ]
    }
   ],
   "source": [
    "TEST_model = pickle.load(open('../Pickles/tfidfvect2.pkl', 'rb'))\n",
    "\n",
    "print(TEST_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf7806bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95438d19",
    "outputId": "190f59a3-8ed5-481e-8ad0-de3cd3baaadd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8093)\t0.03694408830646858\n",
      "  (0, 8089)\t0.021628144918573823\n",
      "  (0, 8050)\t0.0497274539521895\n",
      "  (0, 8049)\t0.11016364582333155\n",
      "  (0, 8042)\t0.04022767162925188\n",
      "  (0, 8035)\t0.013089773516581497\n",
      "  (0, 7986)\t0.017691705351612422\n",
      "  (0, 7934)\t0.01861195231446561\n",
      "  (0, 7931)\t0.015043445572472646\n",
      "  (0, 7925)\t0.03694408830646858\n",
      "  (0, 7919)\t0.01374287660665248\n",
      "  (0, 7901)\t0.013089773516581497\n",
      "  (0, 7846)\t0.025654557793032627\n",
      "  (0, 7844)\t0.03597218816753848\n",
      "  (0, 7768)\t0.026538631430371946\n",
      "  (0, 7694)\t0.06780137453754952\n",
      "  (0, 7636)\t0.03006645541414307\n",
      "  (0, 7613)\t0.018945605044700796\n",
      "  (0, 7530)\t0.03390068726877476\n",
      "  (0, 7501)\t0.01278336564572092\n",
      "  (0, 7500)\t0.05487750586388943\n",
      "  (0, 7492)\t0.15392734675819578\n",
      "  (0, 7486)\t0.08993047041884619\n",
      "  (0, 7398)\t0.03694408830646858\n",
      "  (0, 7348)\t0.026538631430371946\n",
      "  :\t:\n",
      "  (99, 1600)\t0.04946733759450423\n",
      "  (99, 1581)\t0.042484792480827906\n",
      "  (99, 1507)\t0.03625065040130079\n",
      "  (99, 1476)\t0.033199456795716224\n",
      "  (99, 1446)\t0.02629924016155174\n",
      "  (99, 1441)\t0.038916124026496406\n",
      "  (99, 1432)\t0.13632049356928438\n",
      "  (99, 1349)\t0.042484792480827906\n",
      "  (99, 1279)\t0.040551066254828266\n",
      "  (99, 1278)\t0.03749987264924371\n",
      "  (99, 1272)\t0.03156451456738437\n",
      "  (99, 1202)\t0.029505270539074865\n",
      "  (99, 1112)\t0.033199456795716224\n",
      "  (99, 934)\t0.03625065040130079\n",
      "  (99, 923)\t0.026770701356742563\n",
      "  (99, 660)\t0.02889904094218874\n",
      "  (99, 651)\t0.022153661079962823\n",
      "  (99, 557)\t0.04033614206348971\n",
      "  (99, 538)\t0.024212905108272325\n",
      "  (99, 433)\t0.15660927470240338\n",
      "  (99, 356)\t0.040551066254828266\n",
      "  (99, 294)\t0.042484792480827906\n",
      "  (99, 133)\t0.052203091567467795\n",
      "  (99, 98)\t0.038916124026496406\n",
      "  (99, 24)\t0.04485148210835575\n"
     ]
    }
   ],
   "source": [
    "print(X_transformed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56089711",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b35a4a4",
   "metadata": {
    "id": "0f84ef5f"
   },
   "source": [
    "Modeling & Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b30fa",
   "metadata": {
    "id": "7a246d29"
   },
   "source": [
    "### Splitting the data into test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46151891",
   "metadata": {
    "id": "6007c5c2"
   },
   "outputs": [],
   "source": [
    "# Splitting the data into test and train datasets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_transformed, Y, test_size=0.18, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804762c0",
   "metadata": {
    "id": "b653caf9"
   },
   "source": [
    "We use 2 models to determine the accuracy of teh training set and will then select the most accurate model to us ein HEREKO\n",
    "The first Model - Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2953d86a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "1915d04c",
    "outputId": "e7d71995-1315-4f1a-9f58-68e38565346e",
    "tags": [
     "history"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "logisticreg_model = LogisticRegression()\n",
    "\n",
    "logisticreg_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e7c25",
   "metadata": {
    "id": "0a019bc4"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98872c4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "304118ab",
    "outputId": "99ce9aec-a7b9-41f4-eefb-bf84c5d7a992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training data:  1.0\n",
      "Accuracy score on the test data:  0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Score on Training Data\n",
    "X_train_prediction = logisticreg_model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
    "\n",
    "print('Accuracy score on the training data: ',training_data_accuracy)\n",
    "\n",
    "# Accuracy Score on Test Data\n",
    "X_test_prediction = logisticreg_model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
    "\n",
    "print('Accuracy score on the test data: ',test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43f85195",
   "metadata": {
    "id": "e2b32a09"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(logisticreg_model, open('../Pickles/logisticreg_model.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7ded5a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "014c5ef3",
    "outputId": "82bed337-cd23-4c88-f9a5-e3acd47f23c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.88      0.64      0.74        11\\n           1       0.60      0.86      0.71         7\\n\\n    accuracy                           0.72        18\\n   macro avg       0.74      0.75      0.72        18\\nweighted avg       0.77      0.72      0.72        18\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification report for test data\n",
    "classification_report(Y_test, X_test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ea110",
   "metadata": {
    "id": "b26ebf70"
   },
   "source": [
    "**CLASSIFICATION MODEL : PASSIVE AGGRESSIVE CLASSIFIER**\n",
    "\n",
    "* Passive Aggressive Classifier works by responding as passive for correct classifications and responding as aggressive for any miscalculation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98d31885",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c62852b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to preprocess and stem the text\n",
    "def stemming(text):\n",
    "    ps = PorterStemmer()\n",
    "    review = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    return review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dba83559",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply stemming to each text in the array\n",
    "X_preprocessed = [stemming(text) for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59cd2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca87a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the preprocessed data\n",
    "X_transformed = vectorizer.fit_transform(X_preprocessed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fde46919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_transformed, Y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cf722d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "# Creating model\n",
    "passive_aggressive_model = PassiveAggressiveClassifier(C=0.5, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fb1e854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=0.5, random_state=5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fitting model\n",
    "passive_aggressive_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e925ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Making prediction on test set\n",
    "test_pred = passive_aggressive_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbb4b60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy : 63.63636363636363 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "print(f\"Test Set Accuracy : {accuracy_score(Y_test, test_pred) * 100} %\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2abcf779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vectorizer\n",
    "pickle.dump(vectorizer, open('../Pickles/tfidf_vectorizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9170565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "pickle.dump(passive_aggressive_model, open('../Pickles/passive_aggressive_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f850f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained models to make predictions on new data\n",
    "vectorizer = pickle.load(open('../Pickles/tfidf_vectorizer.pkl', 'rb'))\n",
    "passive_aggressive_model = pickle.load(open('../Pickles/passive_aggressive_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ba7fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_new is a new text input\n",
    "X_new = X[5]\n",
    "X_new_preprocessed = stemming(X_new)\n",
    "X_new_transformed = vectorizer.transform([X_new_preprocessed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1336282",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make prediction using the trained model\n",
    "prediction = passive_aggressive_model.predict(X_new_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ed9fbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the new text input:  0\n",
      "Jono says it's True\n"
     ]
    }
   ],
   "source": [
    "# Print the prediction result\n",
    "print(\"Prediction for the new text input: \", prediction[0])\n",
    "if (prediction[0] == 0):\n",
    "    print('Jono says it\\'s True')\n",
    "else:\n",
    "    print('Johan Says it is a porky:)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6cf34f3c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56a14614",
   "metadata": {
    "id": "d486f0ca"
   },
   "outputs": [],
   "source": [
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X_transformed, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30aad454",
   "metadata": {
    "id": "cfd09b49"
   },
   "outputs": [],
   "source": [
    "pickle.dump(passive_aggressive_model, open('../Pickles/passiveagressive_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4217aa3c",
   "metadata": {
    "id": "0eb9e924"
   },
   "source": [
    "Testing the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72bf0a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy : 69.6969696969697 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing modules\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create the vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the input data\n",
    "X_transformed = vectorizer.fit_transform(X)\n",
    "\n",
    "# Splitting dataset into train and test sets\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X_transformed, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Creating model\n",
    "passiveagressive_model = PassiveAggressiveClassifier(C=0.5, random_state=5)\n",
    "\n",
    "# Fitting model\n",
    "passiveagressive_model.fit(X2_train, Y2_train)\n",
    "\n",
    "# Making prediction on test set\n",
    "test_pred = passiveagressive_model.predict(X2_test)\n",
    "\n",
    "# Model evaluation\n",
    "print(f\"Test Set Accuracy : {accuracy_score(Y2_test, test_pred) * 100} %\\n\\n\")\n",
    "\n",
    "# Save the vectorizer\n",
    "pickle.dump(vectorizer, open('../Pickles/tfidf_vectorizer.pkl', 'wb'))\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(passiveagressive_model, open('../Pickles/passiveagressive_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89bda029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 84.85%\n",
      "Prediction for example 500:  0\n",
      "Jono says its True\n"
     ]
    }
   ],
   "source": [
    "y_pred = logisticreg_model.predict(X2_test)\n",
    "\n",
    "# Calculate the prediction accuracy\n",
    "accuracy = np.mean(y_pred == Y2_test) * 100\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Prediction accuracy: {:.2f}%\".format(accuracy))\n",
    "\n",
    "# Print the prediction for a single example\n",
    "X_new = X2_test[5]\n",
    "prediction = logisticreg_model.predict(X_new.reshape(1, -1))\n",
    "print(\"Prediction for example 500: \", prediction[0])\n",
    "if (prediction[0] == 0):\n",
    "  print('Jono says its True')\n",
    "else:\n",
    "  print('Johan Says it is a porky:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee542d9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f35d01a",
    "outputId": "87003203-58d1-468f-febd-08cb3f9497a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 84.85%\n",
      "Prediction for example 500:  0\n",
      "Jono says its True\n"
     ]
    }
   ],
   "source": [
    "y2_pred = logisticreg_model.predict(X2_test)\n",
    "\n",
    "# Calculate the prediction accuracy\n",
    "accuracy = np.mean(y2_pred == Y2_test) * 100\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Prediction accuracy: {:.2f}%\".format(accuracy))\n",
    "\n",
    "# Print the prediction for a single example\n",
    "X2_new = X2_test[5]\n",
    "prediction2 = passiveagressive_model.predict(X2_new.reshape(1, -1))\n",
    "print(\"Prediction for example 500: \", prediction[0])\n",
    "if (prediction[0] == 0):\n",
    "  print('Jono says its True')\n",
    "else:\n",
    "  print('Johan Says it is a porky:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ded013bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "53216c3b",
    "outputId": "b3ddee1f-8b8d-4c16-b4bd-05d12eabacd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_label</th>\n",
       "      <th>text_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Aaron Klein Obama’s Organizing for Action Part...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id  article_label  \\\n",
       "10          10              0   \n",
       "\n",
       "                                          text_corpus  \n",
       "10  Aaron Klein Obama’s Organizing for Action Part...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset[10:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2fbeec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e7f51b5",
    "outputId": "5c86dc3f-cc8f-45a5-961a-7172d3859859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83    1\n",
      "53    0\n",
      "70    0\n",
      "45    0\n",
      "44    0\n",
      "39    0\n",
      "22    1\n",
      "80    0\n",
      "10    0\n",
      "0     1\n",
      "18    1\n",
      "30    0\n",
      "73    1\n",
      "33    0\n",
      "90    0\n",
      "4     1\n",
      "76    1\n",
      "77    0\n",
      "12    1\n",
      "31    1\n",
      "55    0\n",
      "88    1\n",
      "26    1\n",
      "42    1\n",
      "69    1\n",
      "15    0\n",
      "40    0\n",
      "96    0\n",
      "9     0\n",
      "72    1\n",
      "11    0\n",
      "47    0\n",
      "85    1\n",
      "Name: article_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c753f79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c9261cf",
    "outputId": "54f1a90e-b597-4823-b1ac-95ccd39eb9e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83    1\n",
      "53    0\n",
      "70    0\n",
      "45    0\n",
      "44    0\n",
      "39    0\n",
      "22    1\n",
      "80    0\n",
      "10    0\n",
      "0     1\n",
      "18    1\n",
      "30    0\n",
      "73    1\n",
      "33    0\n",
      "90    0\n",
      "4     1\n",
      "76    1\n",
      "77    0\n",
      "12    1\n",
      "31    1\n",
      "55    0\n",
      "88    1\n",
      "26    1\n",
      "42    1\n",
      "69    1\n",
      "15    0\n",
      "40    0\n",
      "96    0\n",
      "9     0\n",
      "72    1\n",
      "11    0\n",
      "47    0\n",
      "85    1\n",
      "Name: article_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee81e358",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "0c6b5a46",
    "outputId": "66f30668-2fac-47d4-a137-34e61c44b8d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_label</th>\n",
       "      <th>text_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [article_id, article_label, text_corpus]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset[300:301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a1faa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     darrel lucu hous dem aid even see comey letter...\n",
      "1     daniel j flynn flynn hillari clinton big woman...\n",
      "2     consortiumnew com truth might get fire truth m...\n",
      "3     jessica purkiss civilian kill singl us airstri...\n",
      "4     howard portnoy iranian woman jail fiction unpu...\n",
      "                            ...                        \n",
      "95    jacey fortin dress like woman mean new york ti...\n",
      "96    brett anderson ella brennan still feed lead ne...\n",
      "97    jane perlez press asia agenda obama tread ligh...\n",
      "98    josh katz democrat percent chanc retak senat n...\n",
      "99    news pr disast presid panason forc resign pana...\n",
      "Name: text_corpus, Length: 100, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer = TfidfVectorizer()\n",
    "# vectorizer.fit(X)\n",
    "\n",
    "vectorizer = pickle.load(open('../Pickles/tfidfvect2.pkl', 'rb'))\n",
    "print(X)\n",
    "vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "839febd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X is an array of text inputs\n",
    "X_preprocessed = [stemming(text) for text in X]  # Apply stemming to each text in the array\n",
    "X_vectorized = vectorizer.transform(X_preprocessed)  # Convert to numerical format using the trained vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71729407",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96a37b98",
    "outputId": "c624e03a-b09b-4801-e8c6-7bd1ca6109a1"
   },
   "outputs": [],
   "source": [
    "pickled_model1 = pickle.load(open('../Pickles/logisticreg_model.pkl', 'rb'))\n",
    "predictions = pickled_model1.predict(X_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2a95d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ab2357c",
    "outputId": "8151f4d9-d005-4d08-c4f7-fdace7e0da51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled_model2 = pickle.load(open('../Pickles/passiveagressive_model.pkl', 'rb'))\n",
    "pickled_model2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e0161",
   "metadata": {
    "id": "170922ea"
   },
   "source": [
    "FAngo tested a point to clarify teh vector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92c8ed22",
   "metadata": {
    "id": "b0287aa5"
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85837835",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "8144960d",
    "outputId": "4b1c42c4-0e78-4936-a1df-b47753a34daa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaron klein obama organ action partner soro link indivis disrupt trump agenda organ action activist group morph barack obama first presidenti campaign partner indivis project onlin train protest presid donald trump agenda last week breitbart news extens report indivis leader openli associ group financ billionair georg soro politico earlier month profil indivis articl titl insid protest movement republican reel news agenc left soro link fail note organ cite articl help amplifi indivis messag either financ directli soro close tie group fund billionair breitbart news document organ action ofa commun organ project sprung obama campaign organ organ america becom nonprofit describ washington post advoc ing presid polici recent facebook post titl take deep breath take action ofa call constitu lobbi particularli hard februari lawmak home district post includ link guid releas indivis organ trump stay tune onlin train invit call coalit partner like indivis guid ofa post state paul sperri write new york post relat manual publish ofa partner indivis advis protest go hall quietli rais alarm grab seat front room sit togeth rather spread pair make seem like whole room oppos republican host posit help reinforc impress broad consensu also urg ask hostil question keep firm hold mic loudli boo gop politician give real answer express concern event host give platform authoritarian racism corrupt say even safest republican deepli alarm sign organ opposit document state action creat impress connect district listen constitu sperri report ofa plan stage ralli across state year attack trump republican obamacar repeal earlier month nbc news report ofa new action partnership indivis ofa hire field organ state home key senat part campaign defend obama signatur healthcar law run campaign group hire saumya narechania former nation field director enrol america work sign peopl obamacar deputi campaign manag ofa say peopl appli spring commun engag fellowship train program previous involv ofa group team indivis buzzi newcom progress movement offer organ train began thursday night video confer combin peopl regist particip train ofa said indivis dc branch implic scuffl last week reportedli injur staffer rep dana rohrabach well reportedli knock ground protest claim deliv valentin day card indivis part coalit activist group slate hold massiv tax march washington least locat april unreport news media list partner support organ march openli financ soro close link soro financ breitbart news document last week meanwhil earlier month politico profil indivis report conserv spread unfound rumor group driven wealthi donor like georg soro politico howev seemingli fail even minim research indivis leader cite news outlet profil person openli associ group financ soro politico fail note organ cite articl help amplifi indivis messag either financ directli soro close tie group fund billionair cite angel padilla group politico report dub indivis group launch way padilla hand fellow aid channel heartbreak manual quash presid donald trump agenda draft protest guid activist full pointer bird dog member congress languag capitol insid manual sinc download one million time indivis say websit local group across nation sign resist trump agenda nearli everi congression district countri manual util form basi protest movement group websit state put guid action show en mass congression district offic event flood congression phone line resist work politico report unfound rumor spread soro involv indivis emphasi ad report hand senior leader count contributor nation organ work insist work volunt basi know conserv spread unfound rumor success driven wealthi donor like georg soro flatli deni paragraph follow follow quot padilla emphasi ad report matter take money alway go get blame soro group even take money soro said padilla analyst nation immigr law center one attack fine indivis yet disclos donor politico fail inform reader nation immigr law center news outlet report padilla serv analyst financ soro open societi foundat center receiv numer open societi grant earmark gener support also unment politico padilla previous serv immigr polici consult radic nation council la raza soro major la raza donor politico went detail indivis aid moveon org aclu news websit fail tell reader moveon org aclu financ soro relev tidbit given politico claim unfound rumor indivis success driven soro news websit report addit moveon org work famili parti join indivis first nationwid call jan nearli peopl phone day accord levin moveon organ director victoria kaplan indivis estim second nation call impact trump immigr order assist aclu padilla group drew peopl politico also miss accord twitter account anoth organ confer call moveon org intern refuge assist project project urban justic center anoth recipi open societi grant taryn higashi execut director center intern refuge assist project current serv advisori board intern migrat initi soro open societi foundat politico report indivis tie organ last month women march fail mention soro reportedli tie partner march also journalist first report march leader close associ soro regard indivis women march politico report indivis also embrac collabor major protest outlet leader group commun women march organ main event jan partnership becom offici march unveil third seri direct action attende ask pursu commun anoth indivis leader mention politico articl jeremi hail report politico hail serv feder advocaci counsel sentenc project sentenc project reportedli financ soro open societi foundat also host project promot caus aaron klein breitbart jerusalem bureau chief senior investig report new york time bestsel author host popular weekend talk radio program aaron klein investig radio follow twitter aaronkleinshow follow facebook'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = re.sub('[^a-zA-Z]', ' ', news_dataset['text_corpus'][10])\n",
    "review = review.lower()\n",
    "review = review.split()\n",
    "    \n",
    "review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "review = ' '.join(review)\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10c9936d",
   "metadata": {
    "id": "79886864"
   },
   "outputs": [],
   "source": [
    "val = vectorizer.transform([review]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a5b0a25",
   "metadata": {
    "id": "884b6a48"
   },
   "outputs": [],
   "source": [
    "tfidfvect2_model2 = pickle.load(open('tfidfvect2.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83e878d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb6daa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2140.826204,
   "end_time": "2021-09-29T17:10:10.602486",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-29T16:34:29.776282",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
