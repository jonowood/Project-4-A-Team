{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24755160",
   "metadata": {
    "id": "8c9cb573"
   },
   "source": [
    "MASTER PYTHON - Using the full training set - Running the learning models take 45 minute each, be patient\n",
    "\n",
    "I added a line from FYANGO that take sthe vectorizer to the app that builds teh external question faster\n",
    "\n",
    "All the models are exported\n",
    "\n",
    "2 models, LOG and AggrO\n",
    "\n",
    "Modify the exisitng models reliably predict if new\n",
    "s is fake or real, using exisitng KAGGEL datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca5946",
   "metadata": {
    "id": "4d5dda4c"
   },
   "source": [
    "#### Dataset used - https://www.kaggle.com/fake-news/data\n",
    "\n",
    "### Dataset Description\n",
    "\n",
    "train.csv: A full training dataset with the following attributes:\n",
    "\n",
    "* id: unique id for a news article\n",
    "* title: the title of a news article\n",
    "* author: author of the news article\n",
    "* text: the text of the article; could be incomplete\n",
    "* label: a label that marks the article as potentially unreliable\n",
    "  * 1: FAKE\n",
    "  * 0: TRUE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9612db7e",
   "metadata": {
    "id": "f47d9fde"
   },
   "source": [
    "Ensure the file creator is installed to save the MODELS for use in Heroku app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc05c85b",
   "metadata": {
    "id": "acdf7db5"
   },
   "source": [
    "Set the dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "643aaced",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/jonowood/Project-4-A-Team/blob/JonBranch/ML/JONO_PREDICT_MASTER.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/jonowood/Project-4-A-Team/blob/JonBranch/ML/JONO_PREDICT_MASTER.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" /> Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f313070",
   "metadata": {
    "id": "7b4b4979"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "from api_keys import postgres_p\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b19d1d8",
   "metadata": {
    "id": "5cbd1c06"
   },
   "source": [
    "The Natural Language Toolkit (NLTK) is a platform used for building Python programs that work with human language data for applying in statistical natural language processing (NLP). It contains text processing libraries for tokenization, parsing, classification, stemming, tagging and semantic reasoning.\n",
    "The nltk.corpus package defines a collection of corpus reader classes, which can be used to access the contents of a diverse set of corpora. The list of available corpora is given at: https://www.nltk.org/nltk_data/ Each corpus reader class is specialized to handle a specific corpus forma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a94e780",
   "metadata": {
    "id": "c32358ea"
   },
   "source": [
    "Load and test all the STW ,Stopwords are words which occur frequently in a corpus. e.g a, an, the, in. Frequently occurring words are removed from the corpus for the purpose of text-normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c392dc4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b3d25c8",
    "outputId": "a174a4ae-f59d-4210-e4b1-32f29afa4c50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jonow\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc9173f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd8da98b",
    "outputId": "2a30bc0b-3d38-431f-dc5a-1be22dfd8839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# check if Stopwords laoded in english\n",
    "\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67432b17",
   "metadata": {
    "id": "a44f0a84"
   },
   "source": [
    "Data Pre-processing and Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1cb37a",
   "metadata": {
    "id": "83fffc5d"
   },
   "source": [
    "Regular Expression Syntax. A regular expression (or RE) specifies a set of strings that matches it; the functions in this module let you check if a particular string matches a given regular expression (or if a given regular expression matches a particular string, which comes down to the same thing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b626a97",
   "metadata": {},
   "source": [
    "# insert SQL here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ea1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(database=\"Project_4\", user=\"postgres\", password=postgres_p) #host=\"your_host_address\", port=\"your_port_number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b838505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL query to retrieve the data\n",
    "query = \"SELECT a.article_id, a.article_label, t.text_corpus FROM article_id a  JOIN text_corpus t ON a.article_id = t.article_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edd6955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query and store the results in a Pandas DataFrame\n",
    "news_dataset = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca1ffc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fd99892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_label</th>\n",
       "      <th>text_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Darrell Lucus House Dem Aide: We Didn’t Even S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Consortiumnews.com Why the Truth Might Get You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Jessica Purkiss 15 Civilians Killed In Single ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Howard Portnoy Iranian woman jailed for fictio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20795</th>\n",
       "      <td>20795</td>\n",
       "      <td>0</td>\n",
       "      <td>Jerome Hudson Rapper T.I.: Trump a ’Poster Chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20796</th>\n",
       "      <td>20796</td>\n",
       "      <td>0</td>\n",
       "      <td>Benjamin Hoffman N.F.L. Playoffs: Schedule, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20797</th>\n",
       "      <td>20797</td>\n",
       "      <td>0</td>\n",
       "      <td>Michael J. de la Merced and Rachel Abrams Macy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20798</th>\n",
       "      <td>20798</td>\n",
       "      <td>1</td>\n",
       "      <td>Alex Ansary NATO, Russia To Hold Parallel Exer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799</th>\n",
       "      <td>20799</td>\n",
       "      <td>1</td>\n",
       "      <td>David Swanson What Keeps the F-35 Alive   Davi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id  article_label  \\\n",
       "0               0              1   \n",
       "1               1              0   \n",
       "2               2              1   \n",
       "3               3              1   \n",
       "4               4              1   \n",
       "...           ...            ...   \n",
       "20795       20795              0   \n",
       "20796       20796              0   \n",
       "20797       20797              0   \n",
       "20798       20798              1   \n",
       "20799       20799              1   \n",
       "\n",
       "                                             text_corpus  \n",
       "0      Darrell Lucus House Dem Aide: We Didn’t Even S...  \n",
       "1      Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...  \n",
       "2      Consortiumnews.com Why the Truth Might Get You...  \n",
       "3      Jessica Purkiss 15 Civilians Killed In Single ...  \n",
       "4      Howard Portnoy Iranian woman jailed for fictio...  \n",
       "...                                                  ...  \n",
       "20795  Jerome Hudson Rapper T.I.: Trump a ’Poster Chi...  \n",
       "20796  Benjamin Hoffman N.F.L. Playoffs: Schedule, Ma...  \n",
       "20797  Michael J. de la Merced and Rachel Abrams Macy...  \n",
       "20798  Alex Ansary NATO, Russia To Hold Parallel Exer...  \n",
       "20799  David Swanson What Keeps the F-35 Alive   Davi...  \n",
       "\n",
       "[20800 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d214d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will separate the data and label i.e. text_corpus and label fields\n",
    "X = news_dataset['text_corpus']\n",
    "Y = news_dataset['article_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d98a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for stemming the content\n",
    "port_stem = PorterStemmer()\n",
    "def stemming(content):\n",
    "    # Pick all alphabet characters - lowercase and uppercase...all others such as numbers and punctuations will be removed. Numbers or punctuations will be replaced by a whitespace\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
    "    # Converting all letters to lowercase \n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    # Converting all to a splitted case or a list\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    # Applying stemming, so we get the root words wherever possible + remove stopwords as well\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    # Join all the words in final content\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a6c0866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply stemming to the text_corpus column\n",
    "X = X.apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e878d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24529202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the X and Y variables\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75d3b2",
   "metadata": {
    "id": "f92318e7"
   },
   "source": [
    "TF-IDF (Term Frequency, Inverse Document Frequency)\n",
    "\n",
    "### Converting Textual data to Numerical data\n",
    "\n",
    "* The TF-IDF Vectorizer\n",
    "* TF-IDF Vectorizer coverts textual data to numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b4176",
   "metadata": {
    "id": "51cc3ef1"
   },
   "source": [
    "Thsi is still a bit messed up and need to be cleaned, I stidued the HEROKYU app fiel and the vectorizer is use dto translate the input text to ML to do teh comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d004944",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "0543b31e",
    "outputId": "f81bb5a9-d380-4a84-9d7a-6e3c892a42bc"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a0705",
   "metadata": {
    "id": "f923e533"
   },
   "outputs": [],
   "source": [
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e5a306",
   "metadata": {
    "id": "YZO9QQZoD8_r"
   },
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open('../Pickles/tfidfvect2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_model = pickle.load(open('../Pickles/tfidfvect2.pkl', 'rb'))\n",
    "\n",
    "print(TEST_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7806bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95438d19",
    "outputId": "190f59a3-8ed5-481e-8ad0-de3cd3baaadd"
   },
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b35a4a4",
   "metadata": {
    "id": "0f84ef5f"
   },
   "source": [
    "Modeling & Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b30fa",
   "metadata": {
    "id": "7a246d29"
   },
   "source": [
    "### Splitting the data into test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46151891",
   "metadata": {
    "id": "6007c5c2"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.18, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804762c0",
   "metadata": {
    "id": "b653caf9"
   },
   "source": [
    "We use 2 models to determine the accuracy of teh training set and will then select the most accurate model to us ein HEREKO\n",
    "The first Model - Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953d86a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "1915d04c",
    "outputId": "e7d71995-1315-4f1a-9f58-68e38565346e",
    "tags": [
     "history"
    ]
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "logisticreg_model = LogisticRegression()\n",
    "\n",
    "logisticreg_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e7c25",
   "metadata": {
    "id": "0a019bc4"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98872c4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "304118ab",
    "outputId": "99ce9aec-a7b9-41f4-eefb-bf84c5d7a992"
   },
   "outputs": [],
   "source": [
    "# Accuracy Score on Training Data\n",
    "X_train_prediction = logisticreg_model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
    "\n",
    "print('Accuracy score on the training data: ',training_data_accuracy)\n",
    "\n",
    "# Accuracy Score on Test Data\n",
    "X_test_prediction = logisticreg_model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
    "\n",
    "print('Accuracy score on the test data: ',test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f85195",
   "metadata": {
    "id": "e2b32a09"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(logisticreg_model, open('../Pickles/logisticreg_model.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ded5a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "014c5ef3",
    "outputId": "82bed337-cd23-4c88-f9a5-e3acd47f23c3"
   },
   "outputs": [],
   "source": [
    "# Classification report for test data\n",
    "classification_report(Y_test, X_test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ea110",
   "metadata": {
    "id": "b26ebf70"
   },
   "source": [
    "**CLASSIFICATION MODEL : PASSIVE AGGRESSIVE CLASSIFIER**\n",
    "\n",
    "* Passive Aggressive Classifier works by responding as passive for correct classifications and responding as aggressive for any miscalculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a14614",
   "metadata": {
    "id": "d486f0ca"
   },
   "outputs": [],
   "source": [
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea76e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56733ec1",
    "outputId": "08614de7-b7e0-4a26-8bcf-6c60c62a2b80"
   },
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting dataset into train and test sets\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Creating model\n",
    "passiveagressive_model = PassiveAggressiveClassifier(C = 0.5, random_state = 5)\n",
    "\n",
    "# Fitting model\n",
    "passiveagressive_model.fit(X2_train, Y2_train)\n",
    "\n",
    "# Making prediction on test set\n",
    "test_pred = passiveagressive_model.predict(X2_test)\n",
    "\n",
    "# Model evaluation\n",
    "print(f\"Test Set Accuracy : {accuracy_score(Y2_test, test_pred) * 100} %\\n\\n\")\n",
    "\n",
    "#print(f\"Classification Report : \\n\\n{classification_report(Y2_test, test_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aad454",
   "metadata": {
    "id": "cfd09b49"
   },
   "outputs": [],
   "source": [
    "pickle.dump(passiveagressive_model, open('../Pickles/passiveagressive_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4217aa3c",
   "metadata": {
    "id": "0eb9e924"
   },
   "source": [
    "Testing the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bda029",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logisticreg_model.predict(X_test)\n",
    "\n",
    "# Calculate the prediction accuracy\n",
    "accuracy = np.mean(y_pred == Y_test) * 100\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Prediction accuracy: {:.2f}%\".format(accuracy))\n",
    "\n",
    "# Print the prediction for a single example\n",
    "X_new = X_test[501]\n",
    "prediction = logisticreg_model.predict(X_new.reshape(1, -1))\n",
    "print(\"Prediction for example 500: \", prediction[0])\n",
    "if (prediction[0] == 0):\n",
    "  print('Jono says its True')\n",
    "else:\n",
    "  print('Johan Says it is a porky:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee542d9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f35d01a",
    "outputId": "87003203-58d1-468f-febd-08cb3f9497a4"
   },
   "outputs": [],
   "source": [
    "y2_pred = logisticreg_model.predict(X2_test)\n",
    "\n",
    "# Calculate the prediction accuracy\n",
    "accuracy = np.mean(y2_pred == Y2_test) * 100\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Prediction accuracy: {:.2f}%\".format(accuracy))\n",
    "\n",
    "# Print the prediction for a single example\n",
    "X2_new = X2_test[501]\n",
    "prediction2 = passiveagressive_model.predict(X2_new.reshape(1, -1))\n",
    "print(\"Prediction for example 500: \", prediction[0])\n",
    "if (prediction[0] == 0):\n",
    "  print('Jono says its True')\n",
    "else:\n",
    "  print('Johan Says it is a porky:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded013bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "53216c3b",
    "outputId": "b3ddee1f-8b8d-4c16-b4bd-05d12eabacd6"
   },
   "outputs": [],
   "source": [
    "news_dataset[100:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fbeec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e7f51b5",
    "outputId": "5c86dc3f-cc8f-45a5-961a-7172d3859859"
   },
   "outputs": [],
   "source": [
    "print(Y_test[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b955a095",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94efd9e9",
    "outputId": "76ebbc05-2ab7-4016-bd29-a358456aab11"
   },
   "outputs": [],
   "source": [
    "X_new = X_test[301]\n",
    "\n",
    "prediction = logisticreg_model.predict(X_new)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "  print('Jono says its True')\n",
    "else:\n",
    "  print('Johan Says it is a porky:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c753f79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c9261cf",
    "outputId": "54f1a90e-b597-4823-b1ac-95ccd39eb9e2"
   },
   "outputs": [],
   "source": [
    "print(Y_test[301])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81e358",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "0c6b5a46",
    "outputId": "66f30668-2fac-47d4-a137-34e61c44b8d2"
   },
   "outputs": [],
   "source": [
    "news_dataset[300:301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532a39b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71729407",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96a37b98",
    "outputId": "c624e03a-b09b-4801-e8c6-7bd1ca6109a1"
   },
   "outputs": [],
   "source": [
    "pickled_model1 = pickle.load(open('logisticreg_model.pkl', 'rb'))\n",
    "pickled_model1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a95d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ab2357c",
    "outputId": "8151f4d9-d005-4d08-c4f7-fdace7e0da51"
   },
   "outputs": [],
   "source": [
    "pickled_model2 = pickle.load(open('passiveagressive_model.pkl', 'rb'))\n",
    "pickled_model2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e0161",
   "metadata": {
    "id": "170922ea"
   },
   "source": [
    "FAngo tested a point to clarify teh vector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8ed22",
   "metadata": {
    "id": "b0287aa5"
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85837835",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "8144960d",
    "outputId": "4b1c42c4-0e78-4936-a1df-b47753a34daa"
   },
   "outputs": [],
   "source": [
    "review = re.sub('[^a-zA-Z]', ' ', news_dataset['text_corpus'][100])\n",
    "review = review.lower()\n",
    "review = review.split()\n",
    "    \n",
    "review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "review = ' '.join(review)\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c9936d",
   "metadata": {
    "id": "79886864"
   },
   "outputs": [],
   "source": [
    "val = vectorizer.transform([review]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b0a25",
   "metadata": {
    "id": "884b6a48"
   },
   "outputs": [],
   "source": [
    "tfidfvect2_model2 = pickle.load(open('tfidfvect2.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2956a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880908d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2140.826204,
   "end_time": "2021-09-29T17:10:10.602486",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-29T16:34:29.776282",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
